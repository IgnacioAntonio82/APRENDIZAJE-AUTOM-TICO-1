{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnacioAntonio82/APRENDIZAJE-AUTOM-TICO-1/blob/main/TP2_REGRESION%2BMLP_Aguilar_Ignacio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP2 AA1\n",
        "\n",
        "**Autor**: **Ignacio Antonio Aguilar**"
      ],
      "metadata": {
        "id": "t4CxvZXx6Dmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indicaciones b√°sicas\n",
        "\n",
        "0) Debe usar este notebook como template para su entrega. Haga una copia y comience a completar las consignas.\n",
        "\n",
        "1) Cada uno debe completar las consignas indicadas en este notebook.\n",
        "\n",
        "2)\n",
        "3) No pueden repetir el mismo dataset que ya haya definido un compa√±ero.\n",
        "\n",
        "4) copias expl√≠citas de secciones enteras del trabajo de otro ser√° penalizado disminuyendo su puntuaci√≥n.\n",
        "\n",
        "5) No se olvide de a√±adir las fuentes de inspiraci√≥n de su c√≥digo (blogs, prompts de chatgpt o similar).\n",
        "\n",
        "6) Adem√°s de todo el c√≥digo que agregue, es importante que sepa interpretarlo. Agregue texto explicativo en cada secci√≥n. Esto le ayudar√° al momento del coloquio / parcial\n",
        "\n",
        "7) Revise las fecha l√≠mite de entrega de este trabajo"
      ],
      "metadata": {
        "id": "BSeucmV-KLmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENTREGA"
      ],
      "metadata": {
        "id": "0qigDO5T90h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* En el foro destinado a la tarea debe postear al menos tres veces:\n",
        "  - La primera vez para indicar el dataset elegido\n",
        "  - Una segunda vez para postear su entrega\n",
        "  - Una tercera vez para brindar feedback a alguien m√°s en el foro.\n",
        "  - Puede comentar m√°s de un posteo de sus compa√±eros siempre y cuando el intercambio sea respetuoso y fruct√≠fero.\n",
        "* Deben postear como soluci√≥n un enlace a su notebook colab p√∫blico y tambi√©n un enlace al mismo notebook alojado en su repositorio GitHub.\n",
        "* Debe sumar el enlace a un video donde muestre su soluci√≥n y explique lo realizado. Duraci√≥n m√°xima: 5 minutos. Puede grabarse a Ud. mismo usando una sesi√≥n de zoom y grabar localmente. Puede subir el video a su youtube personal como privado o Unlisted.\n",
        "* Enlaces no accesibles o enlaces err√≥neos es igual a determinar que la tarea no ha sido entregada. Corrobore la viabilidad de los enlaces que postea.\n"
      ],
      "metadata": {
        "id": "N4Uno_w694De"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tarea: Aplicaci√≥n de Regresi√≥n Lineal y An√°lisis de Importancia de Variables**  \n",
        "**Objetivo**: Aplicar un modelo de regresi√≥n lineal a un dataset de su elecci√≥n, evaluar su rendimiento e identificar las variables m√°s relevantes para la predicci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "# **Instrucciones**:\n",
        "\n",
        "#1. **Selecci√≥n del Dataset**  \n",
        "   - Elijan un dataset de UCI ML Repository del siguiente enlace: https://archive.ics.uci.edu/datasets/?Task=Regression&skip=0&take=10&sort=desc&orderBy=NumHits&search=  \n",
        "   - Requisitos:  \n",
        "     - Debe tener al menos 4 variables num√©ricas continuas (1 target, 3 o m√°s features).  \n",
        "     - Idealmente, que las features tengan distintas escalas o unidades ( no excluyente).\n",
        "     - Revisar en el foro de la tarea que dicho dataset no haya sido ya elegido por otra persona.\n",
        "     - Postee en el foro de la tarea el dataset que eligi√≥. Continue al siguiente punto.  \n",
        "\n"
      ],
      "metadata": {
        "id": "7WAej0Lx6D91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resoluci√≥n:"
      ],
      "metadata": {
        "id": "rTJxJxW28FMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler,RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ErFsKCnVU6a2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## el data set elegido es  Forty Soybean Cultivars from Subsequent Harvests\n",
        "\n",
        "##cargo el data set\n",
        "url=\"https://raw.githubusercontent.com/IgnacioAntonio82/APRENDIZAJE-AUTOM-TICO-1/main/TP2-REGRESION+MLP_Aguilar_Ignacio/data.csv\"\n",
        "df = pd.read_csv(url, sep=',', encoding='latin-1')\n",
        "df.head(10)##Cargo el archivo csv y muestro los primeros 10 registros, para verificar si trae correctamente"
      ],
      "metadata": {
        "id": "gq7zciB78FvY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "ad6268f5-1a49-4056-87fd-94003367b767"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeEncodeError",
          "evalue": "'ascii' codec can't encode character '\\xd3' in position 65: ordinal not in range(128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1450407244.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m##cargo el data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/IgnacioAntonio82/APRENDIZAJE-AUTOM-TICO-1/main/TP2_-_REGRESI√ìN_+_MLP_Aguilar_Ignacio/data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m##Cargo el archivo csv y muestro los primeros 10 registros, para verificar si trae correctamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    533\u001b[0m                                   '_open', req)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1393\u001b[0m                                 context=self._context)\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1336\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1337\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mskips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skip_accept_encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# chunked encoding will happen if HTTP/1.1 is used and either\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mputrequest\u001b[0;34m(self, method, url, skip_host, skip_accept_encoding)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s %s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_encode_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;31m# ASCII also helps prevent CVE-2019-9740.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xd3' in position 65: ordinal not in range(128)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explicacion Significado de Features\n",
        "- Season ‚Üí Campa√±a agr√≠cola / a√±o.\n",
        "\n",
        "- Cultivar ‚Üí Genotipo / variedad / h√≠brido.\n",
        "\n",
        "- Repetition ‚Üí N√∫mero de la repetici√≥n (bloque experimental).\n",
        "\n",
        "- PH ‚Üí Altura de planta (cm).\n",
        "\n",
        "- IFP ‚Üí Inserci√≥n de la primera vaina (cm).\n",
        "\n",
        "- NLP ‚Üí N√∫mero de vainas por planta.\n",
        "\n",
        "- NGP ‚Üí N√∫mero de granos por planta.\n",
        "\n",
        "- NGL ‚Üí N√∫mero de granos por vaina (o l√≥culo).\n",
        "\n",
        "- NS ‚Üí N√∫mero de semillas por vaina / nodo (seg√∫n definici√≥n en tu protocolo).\n",
        "\n",
        "- MHG ‚Üí Peso de 100 semillas (g).\n",
        "\n",
        "- GY ‚Üí Rendimiento en grano (kg/ha, probablemente)."
      ],
      "metadata": {
        "id": "xFPESdd0y7NJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. **An√°lisis exploratorio (previo al modelado)**  \n",
        "   - Describan las variables (media, distribuci√≥n, outliers).  \n",
        "   - Visualizen:  \n",
        "     - Histogramas o boxplots para ver distribuciones.  \n",
        "     - Gr√°ficos de dispersi√≥n (scatterplots) entre features y target.  \n",
        "   - **Pregunta clave**: ¬øQu√© relaciones lineales preliminares observan?  \n"
      ],
      "metadata": {
        "id": "UWnCaDQP7bbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resoluci√≥n:"
      ],
      "metadata": {
        "id": "j5j6RRR4_UHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Estad√≠sticas descriptivas\n",
        "df.describe()\n"
      ],
      "metadata": {
        "id": "9xMXweis_UHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interpretacion de cada variable\n",
        "- count: Hay 320 observaciones\n",
        "### PH (Plant Height = Altura de planta, cm)\n",
        "\n",
        "- Media = 68.4 cm,\n",
        "- Rango = 47.6 ‚Äì 94.8 cm.\n",
        "- 25% < 63 cm, la mayor√≠a de las plantas no supera los 75 cm.\n",
        "- Variabilidad moderada (std 8.96), es decir, no hay diferencias extremas en altura.\n",
        "\n",
        "###IFP (Inflorescence Primary, cm / largo de inflorescencia primaria)\n",
        "\n",
        "- Media = 15.5 cm, rango 7.2 ‚Äì 26.4 cm.\n",
        "- Valores entre 13.6 y 17.3 cm (25‚Äì75%) son lo m√°s frecuente.\n",
        "- Variabilidad moderada (std 3.02).\n",
        "\n",
        "###NLP (N√∫mero de l√≥culos por planta / vainas por planta, seg√∫n el cultivo)\n",
        "\n",
        "- Media = 59.1, rango 20.2 ‚Äì 123.\n",
        "- El 50% de los casos cae entre 44 y 71.\n",
        "- Desviaci√≥n relativamente alta (std 20.1)\n",
        "\n",
        "### NGP (N√∫mero de granos por planta)\n",
        "\n",
        "- Media = 135, pero el m√°ximo llega a 683.4, lo que es un outlier fuerte.\n",
        "- El 50% central est√° entre 95 y 161, valores m√°s razonables.\n",
        "- La dispersi√≥n (std 60.5) es muy alta.\n",
        "\n",
        "### NGL (N√∫mero de granos por l√≥culo / vaina)\n",
        "\n",
        "- Media = 2.29, rango 0.94 ‚Äì 14.86.\n",
        "- La mayor√≠a de los datos se concentran entre 2 y 2.5 (percentiles 25‚Äì75).\n",
        "- El m√°ximo (14.86) parece un valor at√≠pico o error de medici√≥n\n",
        "\n",
        "### NS (N√∫mero de semillas por espiga o similar)\n",
        "\n",
        "- Media = 4.07, rango 0.4 ‚Äì 9.\n",
        "- 50% central entre 3 y 5, lo cual muestra baja dispersi√≥n.\n",
        "- Valores m√≠nimos (0.4) indican plantas muy poco productivas.\n",
        "\n",
        "### MHG (Mil Hojas de Grano o Peso de 1000 granos, g)\n",
        "\n",
        "- Media = 168.3 g, rango 127 ‚Äì 216 g.\n",
        "- La mayor√≠a entre 154 y 183 g (percentiles 25‚Äì75).\n",
        "- Variabilidad moderada (std 19.6).\n",
        "\n",
        "### GY (Grain Yield = rendimiento de grano, kg/ha o g/planta seg√∫n dise√±o)\n",
        "\n",
        "- Media = 3419, rango 1538 ‚Äì 4930.\n",
        "- 50% central entre 3126 y 3708, lo que indica una productividad media-alta.\n",
        "- Desviaci√≥n (503) muestra que hay diferencias importantes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0K9J_Dk_0R2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ZyAPtDAJxibd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "1TygWN7dx50f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar variables categ√≥ricas por tipo de dato (object, category)\n",
        "categorical_vars = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "categorical_vars"
      ],
      "metadata": {
        "id": "x3UtOKCcykfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Histogramas o boxplots para ver distribuciones\n",
        "\n",
        "features = [\"PH\", \"IFP\", \"NLP\", \"NGP\", \"NGL\", \"NS\", \"MHG\", \"GY\"]\n",
        "# Define las variables que quer√©s analizar.\n",
        "\n",
        "for col in features:\n",
        "    plt.figure(figsize=(12,4)) #Crea una nueva figura (gr√°fico) de 12x4 pulgadas para cada variable.\n",
        "\n",
        "    # Histograma\n",
        "    plt.subplot(1,2,1) #Divide la figura en una cuadr√≠cula de subgr√°ficos\n",
        "    sns.histplot(df[col], kde=True, bins=10, color=\"steelblue\")\n",
        "    # Genera un histograma de la columna col del DataFrame df:\n",
        "    # bins=10 ‚Üí divide los valores en 10 intervalos (barras).\n",
        "    #color=\"steelblue\" ‚Üí pinta las barras de azul acero.\n",
        "    # kde=True ‚Üí a√±ade la curva de densidad estimada para ver c√≥mo se distribuyen los datos suavemente\n",
        "    plt.title(f\"Histograma de {col}\")\n",
        "    #Le pone un t√≠tulo din√°mico al gr√°fico\n",
        "\n",
        "    # Boxplot\n",
        "    plt.subplot(1,2,2)\n",
        "    sns.boxplot(x=df[col], color=\"lightgreen\")\n",
        "    plt.title(f\"Boxplot de {col}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "d7bSHbX_4XrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretacion Histograma / Boxplot de Algunos graficos\n",
        "\n",
        "## histograma y un boxplot de la variable PH (Plant Height = Altura de planta)\n",
        "## Histograma\n",
        "- curva aproximadamente normal\n",
        "- es bastante sim√©trica\n",
        "## Boxplot\n",
        "- Outlier: aparece un valor aislado cerca de 95 cm\n",
        "- Bigotes (m√≠n‚Äìm√°x sin outliers): se extienden desde ~48 cm hasta ~92 cm\n",
        "- Mediana: est√° alrededor de 67 cm\n",
        "- Caja (IQR: 25%‚Äì75%): se concentra entre 63 y 74 cm\n",
        "\n",
        "## histograma y un boxplot de IFP (longitud de inflorescencia primaria, en cm)\n",
        "## Histograma\n",
        "- Forma: distribuci√≥n cercana a la normal\n",
        "## Boxplot\n",
        "- Outliers:\n",
        "- - En el extremo bajo: valores cercanos a 7.5‚Äì8 cm, plantas con inflorescencias muy cortas.\n",
        "- - En el extremo alto: varios puntos aislados por encima de 22 cm, llegando hasta ~26 cm\n",
        "- Bigotes (sin outliers): van de ~10 a ~21 cm.\n",
        "- Caja (IQR): concentra el 50% de los datos entre 13.6 y 17.3 cm, lo que indica que la mayor√≠a est√° bien agrupada.\n",
        "\n",
        "# histograma y un boxplot de  NLP (N√∫mero de l√≥culos/vainas por planta):\n",
        "## Histograma\n",
        "- Distribuci√≥n: asim√©trica hacia la derecha\n",
        "## Boxplot\n",
        "- Outliers: aparecen varios puntos aislados en el extremo alto (‚â•115)\n",
        "- Bigotes (sin outliers): se extienden hasta valores cercanos a 110 vainas\n",
        "- Caja (IQR): entre 44 y 71 vainas, abarca el 50% de los datos centrales\n",
        "\n",
        "# histograma y un boxplot de NGP (N√∫mero de granos por planta):\n",
        "## Histograma\n",
        "- Distribuci√≥n: La distribuci√≥n es asim√©trica positiva (sesgada a la derecha)\n",
        "\n",
        "## Boxplot\n",
        "- Outliers: aparecen m√∫ltiples puntos extremos\n",
        "- Bigotes (sin outliers): se extienden hasta valores cercanos a 250‚Äì280.\n",
        "- Caja (IQR): entre ~95 y 160 granos, donde se ubica el 50% de los datos.\n",
        "\n",
        "# histograma y un boxplot de  NGL (N√∫mero de granos por l√≥culo / vaina):\n",
        "## Histograma\n",
        "- Distribuci√≥n: La distribuci√≥n es asim√©trica positiva\n",
        "\n",
        "## Boxplot\n",
        "- El caj√≥n verde muestra que el rango intercuart√≠lico (IQR) va aproximadamente entre 2 y 3.\n",
        "- La mediana est√° cerca de 2,5.\n",
        "- Existen outliers a la derecha: valores de 4, 6 y un caso extremo alrededor de 15.\n",
        "- Tambi√©n se observan algunos outliers menores en la parte baja, aunque pocos.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MRlvyuMJ78qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Scatterplots de features vs target\n",
        "# -------------------------\n",
        "# Scatterplots vs Rendimiento (GY)\n",
        "# -------------------------\n",
        "# Scatterplots interactivos\n",
        "for col in features:  #Recorre todas las columnas listadas en features, excepto la variable GY (porque esa ya se usa como variable de salida en el eje y).\n",
        "    if col != \"GY\":\n",
        "        fig = px.scatter(  #Crea un diagrama de dispersi√≥n\n",
        "            df,\n",
        "            x=col, #el eje X ser√° la variable independiente\n",
        "            y=\"GY\", #el eje Y siempre ser√° el rendimiento\n",
        "            color=\"Cultivar\",   # los puntos se colorean seg√∫n la categor√≠a de Cultivar (esto ayuda a comparar grupos).\n",
        "            title=f\"{col} vs Rendimiento (GY)\", #t√≠tulo din√°mico con el nombre de la variable\n",
        "            template=\"plotly_white\", # estilo limpio con fondo blanco\n",
        "            trendline=\"ols\",          # L√≠nea de regresi√≥n\n",
        "            trendline_scope=\"overall\",# dibuja una sola l√≠nea de tendencia global usando todos los cultivares juntos.\n",
        "            hover_data=df.columns  # para que muestre m√°s info al pasar el mouse\n",
        "        )\n",
        "        fig.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Gdbfo236ctZY",
        "outputId": "5fa35d88-2fba-47de-dc4b-7ee35fde0b51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3461312531.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Scatterplots interactivos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#Recorre todas las columnas listadas en features, excepto la variable GY (porque esa ya se usa como variable de salida en el eje y).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"GY\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         fig = px.scatter(  #Crea un diagrama de dispersi√≥n\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta clave: ¬øQu√© relaciones lineales preliminares observan?\n",
        "\n",
        "El rendimiento en grano (GY) muestra asociaciones positivas principalmente con el n√∫mero de granos por planta (NGP) y el n√∫mero de legumbres por planta (NLP), aunque dichas correlaciones no son muy fuertes. Esto sugiere que el rendimiento no depende de una sola caracter√≠stica, sino que responde a la combinaci√≥n de m√∫ltiples factores, por lo que un an√°lisis multivariado resultar√° m√°s adecuado para explicar su variabilidad.\n",
        "\n"
      ],
      "metadata": {
        "id": "5Z26MmhKemSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Preprocesamiento**  \n",
        "   - Limpieza: Manejen missing values (eliminar, imputar) y outliers (si es necesario).  \n",
        "   - Limpieza: indique cu√°les features descarta. Justifique.\n",
        "   - Indique si usar√° o no variables categ√≥ricas. Justifique. Realice su preprocesamiento adeucado.\n",
        "   - Escalen las features (p.ej., StandardScaler) para comparar coeficientes despu√©s.  \n",
        "   - Dividan en train/test (70-30 o 80-20).  "
      ],
      "metadata": {
        "id": "A1Ajkh2O70cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y7sVuQOm76ix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resoluci√≥n:"
      ],
      "metadata": {
        "id": "28o4EfDd_WQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a7qdTaxy_WQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Detectar valores faltantes ---\n",
        "print(\"Valores faltantes por columna:\")\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# 2. Detectar outliers usando el criterio IQR en las variables num√©ricas\n",
        "outlier_info = {}\n",
        "for col in [\"PH\",\"IFP\",\"NLP\",\"NGP\",\"NGL\",\"NS\",\"MHG\",\"GY\"]:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
        "    outlier_info[col] = len(outliers)\n",
        "\n",
        "missing_values, outlier_info\n",
        "\n"
      ],
      "metadata": {
        "id": "On_Ef-tt_WQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultado: No hay valores nulos, lo que facilita el an√°lisis.\n",
        "###Respecto a los outliers\n",
        "- PH (Altura de planta): 1 outlier.\n",
        "- IFP (√çndice de fecundidad por planta): 9 outliers.\n",
        "- NLP (N¬∫ de legumbres por planta): 5 outliers.\n",
        "- NGP (N¬∫ de granos por planta): 9 outliers.\n",
        "- NGL (N¬∫ de granos por legumbre): 9 outliers.\n",
        "- NS (N¬∫ de semillas por legumbre): 4 outliers.\n",
        "- GY (Rendimiento en grano): 10 outliers.\n",
        "- MHG (Masa de 100 granos): sin outliers detectados.\n",
        "###No parecen ser errores de carga, Conviene no eliminarlos"
      ],
      "metadata": {
        "id": "gcmBSN5B9iL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza: indique cu√°les features descarta. Justifique.\n",
        "\n",
        "#Las features a descartar son:\n",
        "#Repetition: No aporta a la predicci√≥n\n",
        "#Season: no voy a realizar un analisis por a√±o.\n",
        "\n",
        "## elimino los features a descartar\n",
        "df_clean = df.drop(columns=[\"Repetition\", \"Season\"])\n",
        "# Mostrar info y primeras filas\n",
        "df_clean\n"
      ],
      "metadata": {
        "id": "KaWfcL0Y9t-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indique si usar√° o no variables categ√≥ricas. Justifique. Realice su preprocesamiento adecuado.\n",
        "\n",
        "> Voy a utilizar variables categ√≥ricas. En este dataset, la variable categ√≥rica relevante es **Cultivar** (variedad de soja). Su inclusi√≥n es importante, ya que permite capturar diferencias gen√©ticas entre materiales que impactan directamente en el rendimiento. Si se descartara, se perder√≠a informaci√≥n valiosa y se reducir√≠a la capacidad predictiva del modelo.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYg_F-1e_Vro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Escalen las features (p.ej., StandardScaler) para comparar coeficientes despu√©s.\n",
        "#Para poder comparar coeficientes\n",
        "## 1- Codificar la variable categ√≥rica Cultivar (usando One-Hot Encoding).\n",
        "### 2 -Escalar las features num√©ricas con StandardScaler para que est√©n en la misma escala (media = 0, desviaci√≥n est√°ndar = 1)."
      ],
      "metadata": {
        "id": "W5b6uyrILmfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## 4. **Regresi√≥n Lineal**  \n",
        "   - Ajusten un modelo de regresi√≥n lineal (usando `sklearn.linear_model.LinearRegression`).  \n",
        "   - Obtengan:  \n",
        "     - Coeficientes (pesos) del modelo.  \n",
        "     - Evaluar m√©tricas en el set de entrenamiento y en el de testeo: **R¬≤**, MSE (error cuadr√°tico medio), MAE.  \n"
      ],
      "metadata": {
        "id": "8z3BaKBi70w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir X e y\n",
        "X = df_clean.drop(columns=[\"GY\"]) #todas las variables independientes\n",
        "y = df_clean[\"GY\"] #la variable dependiente a predecir\n",
        "\n",
        "# Identificar variables categ√≥ricas y num√©ricas\n",
        "categorical_features = [ \"Cultivar\" ]\n",
        "numeric_features = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "# Preprocesamiento: OneHot para categ√≥ricas, dejar num√©ricas igual\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
        "        #convierte Cultivar en variables dummy (0/1)\n",
        "        #(drop=\"first\")evita multicolinealidad (se elimina la primera categor√≠a como referencia)\n",
        "        (\"num\", RobustScaler(), numeric_features)  # <-- Escalar num√©ricas\n",
        "        # RobustScaler ‚Üí normaliza las variables num√©ricas usando mediana y rango intercuart√≠lico (robusto frente a outliers).\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline con preprocesamiento + regresi√≥n\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "#Aplica un preprocesamiento a los datos de entrada antes de entrenar el modelo\n",
        "#Una vez transformados los datos, entrena un modelo de regresi√≥n lineal con esas variables procesadas\n",
        "\n",
        "\n",
        "# Dividir en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "#Separa 80% de datos para entrenamiento y 20% para test.\n",
        "#random_state=42 ‚Üí hace que la divisi√≥n sea reproducible.\n",
        "\n",
        "# Ajustar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "#Genera predicciones tanto en train como en test.\n",
        "\n",
        "# M√©tricas\n",
        "metrics = {\n",
        "    \"R2_train\": r2_score(y_train, y_train_pred),\n",
        "    \"R2_test\": r2_score(y_test, y_test_pred),\n",
        "    \"MSE_train\": mean_squared_error(y_train, y_train_pred),\n",
        "    \"MSE_test\": mean_squared_error(y_test, y_test_pred),\n",
        "    \"MAE_train\": mean_absolute_error(y_train, y_train_pred),\n",
        "    \"MAE_test\": mean_absolute_error(y_test, y_test_pred),\n",
        "}\n",
        "#calcula las metricas\n",
        "#R¬≤ (train/test) ‚Üí mide cu√°nto del rendimiento (GY) logra explicar el modelo.\n",
        "#MSE (train/test) ‚Üí Mean Squared Error, el error cuadr√°tico medio.\n",
        "  #Penaliza fuerte errores grandes.\n",
        "  #Mientras m√°s chico, mejor.\n",
        "#MAE (train/test) ‚Üí Mean Absolute Error, error absoluto medio.\n",
        "#Da una idea del error promedio en las mismas unidades que la variable objetivo (ej: kg/ha).\n",
        "\n",
        "print(\"üìä M√©tricas del modelo reducido:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "#Recorre el diccionario e imprime cada m√©trica con 4 decimales\n",
        "\n",
        "\n",
        "\n",
        "# Obtener coeficientes con nombres de variables\n",
        "feature_names = model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
        "coefficients = pd.DataFrame({\n",
        "    \"Variable\": feature_names,\n",
        "    \"Coeficiente\": model.named_steps[\"regressor\"].coef_\n",
        "}).sort_values(by=\"Coeficiente\", key=abs, ascending=False)  # Ordenar por importancia\n",
        "# Recupera los nombres de las variables transformadas\n",
        "# Muestra los coeficientes estimados por la regresi√≥n lineal.\n",
        "# Ordena por magnitud absoluta ‚Üí ayuda a ver qu√© variables tienen m√°s impacto en el rendimiento.\n",
        "\n",
        "# Intercepto\n",
        "intercept = model.named_steps[\"regressor\"].intercept_\n",
        "#Obtiene el intercepto del modelo (valor base de GY).\n",
        "\n",
        "print(\"\\nüîπ Intercepto del modelo:\")\n",
        "print(intercept)\n",
        "\n",
        "print(\"\\nüîπ Coeficientes del modelo (ordenados por valor absoluto):\")\n",
        "print(coefficients)"
      ],
      "metadata": {
        "id": "1un0omHRTI0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5. **Importancia de Variables**  \n",
        "   - Analicen los **coeficientes** del modelo:  \n",
        "     - Valores absolutos altos ‚Üí mayor impacto en el target.  \n",
        "     - Signo: Relaci√≥n positiva/negativa con el target.  \n",
        "   - Comparen la magnitud de los coeficientes **escalados** (si usaron features en distintas unidades).  \n",
        "   - **5.1. Opcional**:\n",
        "     Otra forma es \"desordenar\" un feature y ver c√≥mo empeora el modelo. Si al desordenarlo el error aumenta mucho, ese feature era importante. Usen m√©todos como:  \n",
        "     - **Permutation Importance** (de sklearn) para validar importancia. M√°s info en https://scikit-learn.org/stable/modules/permutation_importance.html\n",
        "\n"
      ],
      "metadata": {
        "id": "YpBHmWkt9Yqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resoluci√≥n:"
      ],
      "metadata": {
        "id": "h6IvyHmV9ccg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Valores absolutos grandes ‚Üí cultivares con mayor impacto en el rendimiento esperado.\n",
        "\n",
        "*  Cultivar_96R29 IPRO (coef = -1098) Gran impacto negativo. Si se siembra este cultivar, el rendimiento esperado cae fuertemente respecto de la referencia\n",
        "\n",
        "*  Cultivar_MONSOY 8330I2X (coef = +751) ‚Üí Gran impacto positivo. Asociado con altos rendimientos\n",
        "\n",
        "Coeficientes negativos ‚Üí menor rendimiento esperado que la referencia.\n",
        "\n",
        "Coeficientes positivos ‚Üí mayor rendimiento esperado que la referencia.\n",
        "\n",
        "###Esto indica que la elecci√≥n del cultivar es la principal variable explicativa de la productividad\n",
        "\n",
        "\n",
        "\n",
        ">El modelo muestra que la elecci√≥n del cultivar es, con diferencia, el factor m√°s cr√≠tico que influye en la variable objetivo, y que ciertos tipos provocan un aumento o disminuci√≥n significativo del resultado. Las variables num√©ricas, si bien relevantes, tienen una influencia comparativamente menor en las predicciones del modelo\n"
      ],
      "metadata": {
        "id": "GNX2zdbS9cch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6. **Reflexi√≥n**  \n",
        "   - ¬øCu√°les variables son m√°s importantes seg√∫n el modelo? ¬øCoincide con su an√°lisis exploratorio?  \n",
        "   - ¬øEl modelo tiene buen rendimiento (R¬≤ alto, MSE bajo)? Si no, ¬øa qu√© podr√≠a deberse?  \n",
        "\n"
      ],
      "metadata": {
        "id": "W1TnsxX69h3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resoluci√≥n:"
      ],
      "metadata": {
        "id": "o-4LI7_h9Z4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##¬øCu√°les variables son m√°s importantes seg√∫n el modelo? ¬øCoincide con su an√°lisis exploratorio?\n",
        "\n",
        "Variables m√°s influyentes (coeficientes m√°s grandes en valor absoluto)\n",
        "1. Cultivar ‚Üí es la variable que m√°s explica las diferencias en rendimiento (GY).\n",
        "EJEMPLO:\n",
        "- Cultivar_96R29 IPRO ‚Üí ‚àí1098\n",
        "- Cultivar_MONSOY 8330I2X ‚Üí +751\n",
        "- Cultivar_NK 8100 IPRO ‚Üí ‚àí720\n",
        "- Cultivar_BRASMAX B√îNUS IPRO ‚Üí ‚àí644\n",
        "- Cultivar_FORTALEZA IPRO ‚Üí +623\n",
        "\n",
        "S√≠, porque en el EDA ya se observaba que no exist√≠a una relaci√≥n lineal fuerte entre GY y ninguna variable individual..\n",
        "\n",
        "\n",
        "##¬øEl modelo tiene buen rendimiento (R¬≤ alto, MSE bajo)? Si no, ¬øa qu√© podr√≠a deberse?\n",
        "\n",
        "1. el modelo tiene\n",
        "- R2_train: 0.5885,  R2_test: 0.5229  es un rendimiento moderado. El modelo explica la mitad de la variabilidad en el rendimiento.\n",
        "- El MSE y MAE son relativamente altos, lo que indica que todav√≠a hay bastante error en las predicciones.\n",
        "\n",
        "*  El modelo tiene un rendimiento moderado (aceptable, pero no √≥ptimo). Sirve para explicar patrones generales (ej. cultivar y NGP/MHG como variables clave), pero no alcanza precisi√≥n alta.\n",
        "\n",
        "El rendimiento podria deverse a:\n",
        "  - Relaciones no lineales entre las variables ‚Üí la regresi√≥n lineal no las captura.\n",
        "- Interacciones entre variables (ej. cultivar √ó ambiente) que no fueron incluidas expl√≠citamente.\n",
        "- Factores no medidos (suelo, clima, manejo agron√≥mico) que afectan fuertemente el rendimiento y no est√°n en el dataset.\n",
        "- Outliers que aumentan el error medio, aunque se mitigaron con RobustScaler\n",
        "\n"
      ],
      "metadata": {
        "id": "4ZvMj3P89Z4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Bonus**:  \n",
        "- Prueben eliminar variables \"poco importantes\" y reentrenar el modelo. ¬øMejora el rendimiento?  "
      ],
      "metadata": {
        "id": "cM2tFQD39LsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Revisar coeficientes ordenados por importancia\n",
        "coefficients\n",
        "#Se mira la tabla de coeficientes obtenida en el modelo original para ver cu√°les tienen valores muy peque√±os\n",
        "\n",
        "# 2. Definir un umbral de importancia (ejemplo: |coef| < 0.05 lo consideramos poco relevante)\n",
        "low_importance_vars = coefficients.loc[coefficients[\"Coeficiente\"].abs() < 0.05, \"Variable\"].tolist()\n",
        "print(\"Variables poco importantes a descartar:\", low_importance_vars)\n",
        "\n",
        "# 3. Generar nuevo dataset sin esas variables\n",
        "X_reduced = X.drop(columns=[col for col in numeric_features if f\"num__{col}\" in low_importance_vars])\n",
        "\n",
        "# 4. Redefinir preprocesamiento (OneHot para cultivar + num√©ricas filtradas)\n",
        "numeric_features_reduced = [col for col in numeric_features if f\"num__{col}\" not in low_importance_vars]\n",
        "\n",
        "\n",
        "# Preprocesamiento: OneHot para categ√≥ricas, dejar num√©ricas igual\n",
        "preprocessor_reduced  = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
        "        #convierte Cultivar en variables dummy (0/1)\n",
        "        #(drop=\"first\")evita multicolinealidad (se elimina la primera categor√≠a como referencia)\n",
        "        (\"num\", RobustScaler(), numeric_features)  # <-- Escalar num√©ricas\n",
        "        # RobustScaler ‚Üí normaliza las variables num√©ricas usando mediana y rango intercuart√≠lico (robusto frente a outliers).\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 5 Pipeline con preprocesamiento + regresi√≥n\n",
        "model_reduced = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "#Aplica un preprocesamiento a los datos de entrada antes de entrenar el modelo\n",
        "#Una vez transformados los datos, entrena un modelo de regresi√≥n lineal con esas variables procesadas\n",
        "\n",
        "\n",
        "\n",
        "# Dividir en train y test\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
        "    X_reduced, y, test_size=0.2, random_state=42\n",
        ")\n",
        "#Separa 80% de datos para entrenamiento y 20% para test.\n",
        "#random_state=42 ‚Üí hace que la divisi√≥n sea reproducible.\n",
        "\n",
        "# Ajustar el modelo\n",
        "model_reduced.fit(X_train_r, y_train_r)\n",
        "\n",
        "# Predicciones\n",
        "y_train_pred_r = model_reduced.predict(X_train_r)\n",
        "y_test_pred_r = model_reduced.predict(X_test_r)\n",
        "#Genera predicciones tanto en train como en test.\n",
        "\n",
        "metrics_reduced = {\n",
        "    \"R2_train\": r2_score(y_train_r, y_train_pred_r),\n",
        "    \"R2_test\": r2_score(y_test_r, y_test_pred_r),\n",
        "    \"MSE_train\": mean_squared_error(y_train_r, y_train_pred_r),\n",
        "    \"MSE_test\": mean_squared_error(y_test_r, y_test_pred_r),\n",
        "    \"MAE_train\": mean_absolute_error(y_train_r, y_train_pred_r),\n",
        "    \"MAE_test\": mean_absolute_error(y_test_r, y_test_pred_r),\n",
        "}\n",
        "#calcula las metricas\n",
        "#R¬≤ (train/test) ‚Üí mide cu√°nto del rendimiento (GY) logra explicar el modelo.\n",
        "#MSE (train/test) ‚Üí Mean Squared Error, el error cuadr√°tico medio.\n",
        "  #Penaliza fuerte errores grandes.\n",
        "  #Mientras m√°s chico, mejor.\n",
        "#MAE (train/test) ‚Üí Mean Absolute Error, error absoluto medio.\n",
        "#Da una idea del error promedio en las mismas unidades que la variable objetivo (ej: kg/ha).\n",
        "\n",
        "print(\"üìä M√©tricas del modelo reducido:\")\n",
        "for k, v in metrics_reduced.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "#Recorre el diccionario e imprime cada m√©trica con 4 decimales\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mil-u2Iewns7",
        "outputId": "e2fe4dda-bdb5-4982-a4a5-f7aedb38cbef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'coefficients' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3249369564.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Revisar coeficientes ordenados por importancia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcoefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Se mira la tabla de coeficientes obtenida en el modelo original para ver cu√°les tienen valores muy peque√±os\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2. Definir un umbral de importancia (ejemplo: |coef| < 0.05 lo consideramos poco relevante)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'coefficients' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Conclusi√≥n:\n",
        "El modelo reducido no mejora el rendimiento. ‚Üí porque todas aportan cierta informaci√≥n √∫til. Mantener todas las variables (aunque algunas sean poco relevantes) parece ser la mejor opci√≥n en este caso."
      ],
      "metadata": {
        "id": "l8R1sNrp9QyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **Tips**:  \n",
        "- Si el R¬≤ es muy bajo, revisen si hay relaciones no lineales (y consideren transformar features).  \n",
        "- Documenten cada paso: ¬°la trazabilidad es clave en ciencia de datos!  \n"
      ],
      "metadata": {
        "id": "_kTXcnnw9vQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S5JHZvSnRkqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† TP2 REGRESION + MLP"
      ],
      "metadata": {
        "id": "wfbDtepTRSul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# REGRESI√ìN CON MLP (scikit-learn)\n",
        "# ============================\n",
        "\n",
        "#  Importar librer√≠as\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "print(\"Dimensiones del dataset:\", df_clean.shape)\n",
        "print(\"Columnas:\", df_clean.columns.tolist())\n",
        "df_clean.head()\n",
        "\n",
        "#  Definir variables predictoras (X) y target (y)\n",
        "target = 'GY'\n",
        "X = df_clean.drop(columns=[target])\n",
        "y = df_clean[target]\n",
        "\n",
        "#  Identificar variables num√©ricas y categ√≥ricas\n",
        "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "num_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "print(f\"Variables categ√≥ricas: {cat_features}\")\n",
        "print(f\"Variables num√©ricas: {num_features}\")\n",
        "\n",
        "#  Crear preprocesador (OneHotEncoder + RobustScaler)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features),\n",
        "        ('num', RobustScaler(), num_features)\n",
        "    ]\n",
        ")\n",
        "#OneHotEncoder a las variables categ√≥ricas (convierte texto en variables binarias).\n",
        "# RobustScaler a las num√©ricas (normaliza sin verse afectado por outliers).\n",
        "\n",
        "#  Crear pipeline completo: preprocesamiento + modelo MLP\n",
        "mlp = MLPRegressor(\n",
        "    hidden_layer_sizes=(64, 32), #2 capas ocultas: 64 y 32 neuronas\n",
        "    activation='relu', #Funci√≥n de activaci√≥n: ReLU.\n",
        "    solver='adam', #Optimizador: Adam\n",
        "    max_iter=1000, #M√°ximo de 1000 iteraciones.\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp)\n",
        "])\n",
        "# Preprocesa los datos.\n",
        "\n",
        "\n",
        "#  Dividir datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "#  Entrenar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#  Evaluar\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "#Calcula m√©tricas de desempe√±o , error promedio cuadr√°tico y  coeficiente de determinaci√≥n qu√© tan bien se ajusta el modelo a los datos (1.0 = perfecto)\n",
        "\n",
        "print(f\"\\nError cuadr√°tico medio (MSE): {mse:.4f}\")\n",
        "print(f\"Coeficiente de determinaci√≥n (R¬≤): {r2:.4f}\")\n",
        "\n",
        "#  Gr√°fico: reales vs predichos\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicci√≥n (GY)\")\n",
        "plt.title(\"GY: valores reales vs predichos\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#Si los puntos siguen la l√≠nea roja diagonal, el modelo predice bien\n",
        "\n",
        "#  Curva de p√©rdida\n",
        "mlp_model = model.named_steps['mlp']\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(mlp_model.loss_curve_)\n",
        "plt.title(\"Curva de p√©rdida durante el entrenamiento\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#Muestra c√≥mo disminuye la p√©rdida (error) durante el entrenamiento. Una curva descendente indica aprendizaje; si se estabiliza, el modelo ha convergido."
      ],
      "metadata": {
        "id": "xEQv6jkPTBOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Caso base (modelo equilibrado)\n",
        "\n",
        "MSE: 124,221.48\n",
        "\n",
        "R¬≤: 0.5202\n",
        "\n",
        "‚û°Ô∏è El modelo logra explicar alrededor del 52% de la variabilidad, lo que sugiere un ajuste moderado: no perfecto, pero razonable.\n",
        "No hay evidencia clara de sobreajuste ni subajuste en este punto."
      ],
      "metadata": {
        "id": "csEfrIkqY-ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Presentar un caso donde la MLP sobreajuste"
      ],
      "metadata": {
        "id": "0ye53D4CUibl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CASO DE SOBREAJUSTE (OVERFITTING)\n",
        "# ==============================\n",
        "\n",
        "#  Dividir datos (poco entrenamiento para provocar sobreajuste)\n",
        "# S√≥lo 20% para entrenamiento (el 80% restante es para prueba/test)\n",
        "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
        "    X, y, test_size=0.8, random_state=42\n",
        ")\n",
        "\n",
        "#  Crear un modelo MLP MUY grande (demasiada capacidad)\n",
        "mlp_overfit = MLPRegressor(\n",
        "    hidden_layer_sizes=(256, 128, 64, 32, 16),  # muchas capas y neuronas\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=3000, #3000 iteracciones\n",
        "    random_state=42,\n",
        "    tol=1e-5 # Tolerancia baja (tol=1e-5), para que el entrenamiento siga hasta alcanzar una p√©rdida muy peque√±a\n",
        ")\n",
        "\n",
        "#  Crear pipeline con preprocesamiento + modelo\n",
        "model_overfit = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp_overfit)\n",
        "])\n",
        "#El Pipeline garantiza que se apliquen los mismos pasos de preprocesamiento (OneHotEncoder + escalado) en los datos de entrenamiento y prueba.\n",
        "\n",
        "#  Entrenar\n",
        "print(\"Entrenando MLP con capacidad alta y pocos datos...\")\n",
        "model_overfit.fit(X_train_small, y_train_small)\n",
        "#Con tan pocos datos y tanta capacidad, el modelo va a ‚Äúaprender‚Äù perfectamente los datos de entrenamiento ‚Äîes decir, los memoriza.\n",
        "\n",
        "#  Evaluar en train y test\n",
        "y_train_pred = model_overfit.predict(X_train_small)\n",
        "y_test_pred = model_overfit.predict(X_test_small)\n",
        "\n",
        "# Se calculan las m√©tricas en ambos conjuntos:\n",
        "mse_train = mean_squared_error(y_train_small, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test_small, y_test_pred)\n",
        "r2_train = r2_score(y_train_small, y_train_pred)\n",
        "r2_test = r2_score(y_test_small, y_test_pred)\n",
        "\n",
        "print(\"\\n=== RESULTADOS DE SOBREAJUSTE ===\")\n",
        "print(f\"Entrenamiento ‚Üí MSE: {mse_train:.4f} | R¬≤: {r2_train:.4f}\")\n",
        "print(f\"Prueba        ‚Üí MSE: {mse_test:.4f} | R¬≤: {r2_test:.4f}\")\n",
        "\n",
        "#  Gr√°fico: valores reales vs predichos (test)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test_small, y_test_pred, alpha=0.7, color='orange')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicci√≥n (GY)\")\n",
        "plt.title(\"Caso de sobreajuste - Datos de prueba\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#  Curva de p√©rdida\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(model_overfit.named_steps['mlp'].loss_curve_)\n",
        "plt.title(\"Curva de p√©rdida (sobreajuste)\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "40n1mxZpUiCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo es demasiado complejo para la cantidad de datos. Aprende el ruido del conjunto de entrenamiento y generaliza mal a datos nuevos. R Train2‚Äã  es alto, R Test2‚Äã  es significativamente bajo.  MSE Train bajo, MSE Test alto\n",
        "\n",
        "## En el conjunto de entrenamiento\n",
        "\n",
        "MSE = 21.6 ‚Üí el error promedio es pr√°cticamente nulo.\n",
        "\n",
        "R¬≤ = 0.9999 ‚Üí el modelo explica el 99.99% de la variabilidad de los datos de entrenamiento.\n",
        "\n",
        "üëâ Eso significa que el modelo ha memorizado completamente los datos que vio durante el entrenamiento.\n",
        "Es decir, ajust√≥ a la perfecci√≥n los pocos puntos de entrenamiento.\n",
        "\n",
        "## En el conjunto de prueba\n",
        "\n",
        "MSE = 442,161.55 ‚Üí el error medio cuadr√°tico es enorme, miles de veces mayor que en entrenamiento.\n",
        "\n",
        "R¬≤ = -0.8440 ‚Üí valor negativo, lo cual es muy malo.\n",
        "\n",
        "‚ö†Ô∏è Cuando R¬≤ < 0, significa que el modelo predice peor que una l√≠nea horizontal constante (es decir, peor que simplemente predecir el promedio de los valores de ‚ÄúGY‚Äù).\n",
        "\n",
        "En otras palabras:\n",
        "\n",
        "La red neuronal no aprendi√≥ a generalizar. Solo repite lo que ve en el entrenamiento y falla con datos nuevos.\n"
      ],
      "metadata": {
        "id": "KOAX7MmYZ9wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 2.3 Presentar un caso donde la MLP subajuste"
      ],
      "metadata": {
        "id": "wX2HfZWpW2j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CASO DE SUBAJUSTE (UNDERFITTING)\n",
        "# ==============================\n",
        "\n",
        "#  Dividir datos (divisi√≥n est√°ndar)\n",
        "# Usaremos una divisi√≥n est√°ndar para que haya suficientes datos de entrenamiento\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42  # 80% entrenamiento, 20% prueba\n",
        ")\n",
        "\n",
        "#  Crear un modelo MLP MUY peque√±o (poca capacidad)\n",
        "# Una sola capa con muy pocas neuronas y pocas iteraciones.\n",
        "mlp_underfit = MLPRegressor(\n",
        "    hidden_layer_sizes=(5,),  # Solo 5 neuronas en 1 capa (baja capacidad)\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=50,              # Muy pocas iteraciones (detiene el aprendizaje pronto)\n",
        "    random_state=42,\n",
        "    tol=0.1                   # Mayor tolerancia para que se detenga r√°pidamente\n",
        ")\n",
        "\n",
        "#  Crear pipeline con preprocesamiento + modelo\n",
        "model_underfit = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp_underfit)\n",
        "])\n",
        "\n",
        "#  Entrenar\n",
        "print(\"Entrenando MLP con capacidad baja y pocas iteraciones...\")\n",
        "model_underfit.fit(X_train, y_train) #Ajusta los par√°metros del modelo a los datos de entrenamiento.\n",
        "#Pero como el modelo tiene poca capacidad y pocas iteraciones,aprende solo patrones muy generales o incluso ninguno.\n",
        "\n",
        "#  Evaluar en train y test\n",
        "y_train_pred = model_underfit.predict(X_train)\n",
        "y_test_pred = model_underfit.predict(X_test)\n",
        "\n",
        "#calcula las metricas\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n=== RESULTADOS DE SUBAJUSTE ===\")\n",
        "print(f\"Entrenamiento ‚Üí MSE: {mse_train:.4f} | R¬≤: {r2_train:.4f}\")\n",
        "print(f\"Prueba        ‚Üí MSE: {mse_test:.4f} | R¬≤: {r2_test:.4f}\")\n",
        "\n",
        "#  Gr√°fico: valores reales vs predichos (test)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, color='purple')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicci√≥n (GY)\")\n",
        "plt.title(\"Caso de subajuste - Datos de prueba\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#  Curva de p√©rdida\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(model_underfit.named_steps['mlp'].loss_curve_)\n",
        "plt.title(\"Curva de p√©rdida (subajuste)\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OGGIaTLyW7bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo MLP configurado con una sola capa oculta de 5 neuronas, pocas iteraciones y una alta tolerancia present√≥ un rendimiento deficiente tanto en entrenamiento como en prueba (MSE elevados y R¬≤ negativos).\n",
        "Esto indica que el modelo tiene insuficiente capacidad y entrenamiento para capturar las relaciones existentes en los datos.\n",
        "En consecuencia, las predicciones son pr√°cticamente aleatorias o muy cercanas al promedio, sin reflejar patrones significativos.\n",
        "\n",
        "üê¢Caso de subajuste (Underfitting)\n",
        "- Entrenamiento ‚Üí MSE: 11,945,301.75 | R¬≤: -46.68\n",
        "- Prueba ‚Üí MSE: 11,869,827.10 | R¬≤: -44.84\n",
        "\n",
        "‚û°Ô∏è El modelo tiene errores muy grandes y R¬≤ negativos tanto en entrenamiento como en prueba.\n",
        "Esto demuestra que no aprendi√≥ los patrones de los datos, produciendo predicciones cercanas al promedio sin relaci√≥n real con la variable objetivo.\n",
        "Por lo tanto, subajusta (underfitting).\n",
        "\n"
      ],
      "metadata": {
        "id": "FsPaqIu5Ztjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 2.4 Presentar el caso donde cree que la MLP funciona de forma aceptable"
      ],
      "metadata": {
        "id": "-PCfqlFTXhwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# CASO DE RENDIMIENTO ACEPTABLE (BUEN AJUSTE)\n",
        "# ====================================\n",
        "\n",
        "#  Dividir datos (divisi√≥n est√°ndar)\n",
        "# Usamos una divisi√≥n est√°ndar para tener suficientes datos de entrenamiento y prueba.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42  # 80% entrenamiento, 20% prueba\n",
        ")\n",
        "\n",
        "#  Crear un modelo MLP con capacidad MODERADA\n",
        "mlp_balanced = MLPRegressor(\n",
        "    hidden_layer_sizes=(64, 32, 16),  # 3 capas ocultas con 64, 32 y 16 neuronas ‚Üí suficiente capacidad para aprender, pero no excesiva\n",
        "    activation='relu',                #Funci√≥n de activaci√≥n ReLU, que permite modelar relaciones no lineales.\n",
        "    solver='adam',\n",
        "    alpha=0.001,                      # Regularizaci√≥n L2 para penalizar pesos y mejorar la generalizaci√≥n\n",
        "    max_iter=1000,                    # M√°ximo de 1000 iteraciones: l√≠mite razonable para permitir la convergencia\n",
        "    n_iter_no_change=20,              # Parada anticipada: si el score no mejora en 20 iteraciones, se detiene\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#  Crear pipeline con preprocesamiento + modelo\n",
        "model_balanced = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp_balanced)\n",
        "])\n",
        "# Combina el preprocesamiento de datos (OneHotEncoder para variables categ√≥ricas + escalado para num√©ricas) con el modelo neuronal MLP.\n",
        "# As√≠, el flujo completo de datos se maneja autom√°ticamente\n",
        "\n",
        "#  Entrenar\n",
        "print(\"Entrenando MLP con capacidad moderada y regularizaci√≥n...\")\n",
        "model_balanced.fit(X_train, y_train)\n",
        "\n",
        "#  Evaluar en train y test\n",
        "y_train_pred = model_balanced.predict(X_train)\n",
        "y_test_pred = model_balanced.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "#Se calcula el error y la capacidad de predicci√≥n en entrenamiento y prueba:\n",
        "\n",
        "print(\"\\n=== RESULTADOS DE RENDIMIENTO ACEPTABLE ===\")\n",
        "print(f\"Entrenamiento ‚Üí MSE: {mse_train:.4f} | R¬≤: {r2_train:.4f}\")\n",
        "print(f\"Prueba        ‚Üí MSE: {mse_test:.4f} | R¬≤: {r2_test:.4f}\")\n",
        "print(\"---\")\n",
        "print(f\"Diferencia de R¬≤ (Train - Test): {r2_train - r2_test:.4f}\")\n",
        "\n",
        "#  Gr√°fico: valores reales vs predichos (test)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, color='green')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicci√≥n (GY)\")\n",
        "plt.title(\"Caso de ajuste aceptable - Datos de prueba\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#  Curva de p√©rdida\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(model_balanced.named_steps['mlp'].loss_curve_)\n",
        "plt.title(\"Curva de p√©rdida (ajuste aceptable)\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ALtKTbYxXjx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo tiene una capacidad adecuada y generaliza bien. El rendimiento en entrenamiento y prueba es similar y alto. La diferencia entre ellos es m√≠nima, lo que indica que el modelo ha aprendido bien los patrones del entrenamiento y tiene una excelente capacidad de generalizaci√≥n.  R¬≤ Train ‚âà R¬≤ Test,  MSE bajos y parecidos\n",
        "\n",
        "üß† Interpretaci√≥n conceptual\n",
        "\n",
        "El Error cuadr√°tico medio (MSE) es relativamente bajo y similar en entrenamiento y prueba, lo que indica que el modelo no est√° ni sobreajustando ni subajustando.\n",
        "\n",
        "El R¬≤ ‚âà 0.6 en ambos conjuntos sugiere que el modelo explica aproximadamente el 60% de la variabilidad de la variable objetivo (GY), lo cual se considera un ajuste razonablemente bueno en contextos con datos reales (donde siempre existe ruido o variabilidad no explicada).\n",
        "\n"
      ],
      "metadata": {
        "id": "oVF-7H51ZmAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "2.5 Agregue sus conclusiones comparando la experiencia y resultados del modelo de regresi√≥n lineal con el modelo del punto 2.4"
      ],
      "metadata": {
        "id": "_Wk-V2qZZb0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An√°lisis Comparativo\n",
        "### Rendimiento Predictivo (R2):\n",
        "-  La MLP logra un R 2\n",
        "  de prueba (0.5973) que es ligeramente superior al de la Regresi√≥n Lineal (0.5229). La mejora es modesta, pero indica que la MLP est√° capturando m√°s variabilidad de la variable objetivo (GY).\n",
        "- Ambos modelos tienen un R 2\n",
        "  por debajo de 0.60, lo que sugiere que ambos modelos est√°n subajustando en cierta medida, es decir, no est√°n capturando completamente la complejidad de los datos (la varianza explicada sigue siendo baja).\n",
        "\n",
        "### Precisi√≥n del Error (MSE):\n",
        "- El MSE de la MLP (104270) es significativamente menor que el de la Regresi√≥n Lineal (123529), lo que significa que, en promedio, el error cuadr√°tico de la MLP es menor. Esto confirma que la MLP es una mejor herramienta predictiva, aunque la ganancia en R 2  no sea dram√°tica.\n",
        "\n",
        "### Capacidad de Generalizaci√≥n (Diferencia R 2 ):\n",
        "\n",
        "- Este es el punto m√°s fuerte de la MLP. La diferencia entre R Train2‚Äã  y R\n",
        "Test2‚Äã  es de solo 0.0017 para la MLP, mientras que en la Regresi√≥n Lineal es de 0.0656. Esto indica que la MLP ha logrado un equilibrio de generalizaci√≥n casi perfecto. La MLP no est√° aprendiendo el ruido y funciona casi id√©nticamente en datos vistos y no vistos. La Regresi√≥n Lineal, aunque simple, mostr√≥ una ca√≠da m√°s pronunciada en la generalizaci√≥n.\n",
        "\n",
        "\n",
        "###  Conclusi√≥n Final\n",
        "\n",
        "El modelo de Red Neuronal MLP (con R2 ‚âà0.60) es el modelo superior para este dataset. Ofreciendo un balance √≥ptimo entre precisi√≥n predictiva y capacidad de generalizaci√≥n, frente a la Regresi√≥n Lineal que resulta m√°s limitada en ambos aspectos.\n"
      ],
      "metadata": {
        "id": "S9iCKgMubPr7"
      }
    }
  ]
}