{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnacioAntonio82/APRENDIZAJE-AUTOM-TICO-1/blob/main/TP2_REGRESION%2BMLP_Aguilar_Ignacio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP2 AA1\n",
        "\n",
        "**Autor**: **Ignacio Antonio Aguilar**"
      ],
      "metadata": {
        "id": "t4CxvZXx6Dmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indicaciones básicas\n",
        "\n",
        "0) Debe usar este notebook como template para su entrega. Haga una copia y comience a completar las consignas.\n",
        "\n",
        "1) Cada uno debe completar las consignas indicadas en este notebook.\n",
        "\n",
        "2)\n",
        "3) No pueden repetir el mismo dataset que ya haya definido un compañero.\n",
        "\n",
        "4) copias explícitas de secciones enteras del trabajo de otro será penalizado disminuyendo su puntuación.\n",
        "\n",
        "5) No se olvide de añadir las fuentes de inspiración de su código (blogs, prompts de chatgpt o similar).\n",
        "\n",
        "6) Además de todo el código que agregue, es importante que sepa interpretarlo. Agregue texto explicativo en cada sección. Esto le ayudará al momento del coloquio / parcial\n",
        "\n",
        "7) Revise las fecha límite de entrega de este trabajo"
      ],
      "metadata": {
        "id": "BSeucmV-KLmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENTREGA"
      ],
      "metadata": {
        "id": "0qigDO5T90h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* En el foro destinado a la tarea debe postear al menos tres veces:\n",
        "  - La primera vez para indicar el dataset elegido\n",
        "  - Una segunda vez para postear su entrega\n",
        "  - Una tercera vez para brindar feedback a alguien más en el foro.\n",
        "  - Puede comentar más de un posteo de sus compañeros siempre y cuando el intercambio sea respetuoso y fructífero.\n",
        "* Deben postear como solución un enlace a su notebook colab público y también un enlace al mismo notebook alojado en su repositorio GitHub.\n",
        "* Debe sumar el enlace a un video donde muestre su solución y explique lo realizado. Duración máxima: 5 minutos. Puede grabarse a Ud. mismo usando una sesión de zoom y grabar localmente. Puede subir el video a su youtube personal como privado o Unlisted.\n",
        "* Enlaces no accesibles o enlaces erróneos es igual a determinar que la tarea no ha sido entregada. Corrobore la viabilidad de los enlaces que postea.\n"
      ],
      "metadata": {
        "id": "N4Uno_w694De"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tarea: Aplicación de Regresión Lineal y Análisis de Importancia de Variables**  \n",
        "**Objetivo**: Aplicar un modelo de regresión lineal a un dataset de su elección, evaluar su rendimiento e identificar las variables más relevantes para la predicción.\n",
        "\n",
        "---\n",
        "\n",
        "# **Instrucciones**:\n",
        "\n",
        "#1. **Selección del Dataset**  \n",
        "   - Elijan un dataset de UCI ML Repository del siguiente enlace: https://archive.ics.uci.edu/datasets/?Task=Regression&skip=0&take=10&sort=desc&orderBy=NumHits&search=  \n",
        "   - Requisitos:  \n",
        "     - Debe tener al menos 4 variables numéricas continuas (1 target, 3 o más features).  \n",
        "     - Idealmente, que las features tengan distintas escalas o unidades ( no excluyente).\n",
        "     - Revisar en el foro de la tarea que dicho dataset no haya sido ya elegido por otra persona.\n",
        "     - Postee en el foro de la tarea el dataset que eligió. Continue al siguiente punto.  \n",
        "\n"
      ],
      "metadata": {
        "id": "7WAej0Lx6D91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolución:"
      ],
      "metadata": {
        "id": "rTJxJxW28FMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler,RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ErFsKCnVU6a2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## el data set elegido es  Forty Soybean Cultivars from Subsequent Harvests\n",
        "\n",
        "##cargo el data set\n",
        "url=\"https://raw.githubusercontent.com/IgnacioAntonio82/APRENDIZAJE-AUTOM-TICO-1/main/TP2-REGRESION+MLP_Aguilar_Ignacio/data.csv\"\n",
        "df = pd.read_csv(url, sep=',', encoding='latin-1')\n",
        "df.head(10)##Cargo el archivo csv y muestro los primeros 10 registros, para verificar si trae correctamente"
      ],
      "metadata": {
        "id": "gq7zciB78FvY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "ad6268f5-1a49-4056-87fd-94003367b767"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeEncodeError",
          "evalue": "'ascii' codec can't encode character '\\xd3' in position 65: ordinal not in range(128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1450407244.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m##cargo el data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/IgnacioAntonio82/APRENDIZAJE-AUTOM-TICO-1/main/TP2_-_REGRESIÓN_+_MLP_Aguilar_Ignacio/data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m##Cargo el archivo csv y muestro los primeros 10 registros, para verificar si trae correctamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    533\u001b[0m                                   '_open', req)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1393\u001b[0m                                 context=self._context)\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1336\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1337\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mskips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skip_accept_encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# chunked encoding will happen if HTTP/1.1 is used and either\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mputrequest\u001b[0;34m(self, method, url, skip_host, skip_accept_encoding)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s %s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_encode_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;31m# ASCII also helps prevent CVE-2019-9740.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xd3' in position 65: ordinal not in range(128)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explicacion Significado de Features\n",
        "- Season → Campaña agrícola / año.\n",
        "\n",
        "- Cultivar → Genotipo / variedad / híbrido.\n",
        "\n",
        "- Repetition → Número de la repetición (bloque experimental).\n",
        "\n",
        "- PH → Altura de planta (cm).\n",
        "\n",
        "- IFP → Inserción de la primera vaina (cm).\n",
        "\n",
        "- NLP → Número de vainas por planta.\n",
        "\n",
        "- NGP → Número de granos por planta.\n",
        "\n",
        "- NGL → Número de granos por vaina (o lóculo).\n",
        "\n",
        "- NS → Número de semillas por vaina / nodo (según definición en tu protocolo).\n",
        "\n",
        "- MHG → Peso de 100 semillas (g).\n",
        "\n",
        "- GY → Rendimiento en grano (kg/ha, probablemente)."
      ],
      "metadata": {
        "id": "xFPESdd0y7NJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. **Análisis exploratorio (previo al modelado)**  \n",
        "   - Describan las variables (media, distribución, outliers).  \n",
        "   - Visualizen:  \n",
        "     - Histogramas o boxplots para ver distribuciones.  \n",
        "     - Gráficos de dispersión (scatterplots) entre features y target.  \n",
        "   - **Pregunta clave**: ¿Qué relaciones lineales preliminares observan?  \n"
      ],
      "metadata": {
        "id": "UWnCaDQP7bbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolución:"
      ],
      "metadata": {
        "id": "j5j6RRR4_UHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Estadísticas descriptivas\n",
        "df.describe()\n"
      ],
      "metadata": {
        "id": "9xMXweis_UHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interpretacion de cada variable\n",
        "- count: Hay 320 observaciones\n",
        "### PH (Plant Height = Altura de planta, cm)\n",
        "\n",
        "- Media = 68.4 cm,\n",
        "- Rango = 47.6 – 94.8 cm.\n",
        "- 25% < 63 cm, la mayoría de las plantas no supera los 75 cm.\n",
        "- Variabilidad moderada (std 8.96), es decir, no hay diferencias extremas en altura.\n",
        "\n",
        "###IFP (Inflorescence Primary, cm / largo de inflorescencia primaria)\n",
        "\n",
        "- Media = 15.5 cm, rango 7.2 – 26.4 cm.\n",
        "- Valores entre 13.6 y 17.3 cm (25–75%) son lo más frecuente.\n",
        "- Variabilidad moderada (std 3.02).\n",
        "\n",
        "###NLP (Número de lóculos por planta / vainas por planta, según el cultivo)\n",
        "\n",
        "- Media = 59.1, rango 20.2 – 123.\n",
        "- El 50% de los casos cae entre 44 y 71.\n",
        "- Desviación relativamente alta (std 20.1)\n",
        "\n",
        "### NGP (Número de granos por planta)\n",
        "\n",
        "- Media = 135, pero el máximo llega a 683.4, lo que es un outlier fuerte.\n",
        "- El 50% central está entre 95 y 161, valores más razonables.\n",
        "- La dispersión (std 60.5) es muy alta.\n",
        "\n",
        "### NGL (Número de granos por lóculo / vaina)\n",
        "\n",
        "- Media = 2.29, rango 0.94 – 14.86.\n",
        "- La mayoría de los datos se concentran entre 2 y 2.5 (percentiles 25–75).\n",
        "- El máximo (14.86) parece un valor atípico o error de medición\n",
        "\n",
        "### NS (Número de semillas por espiga o similar)\n",
        "\n",
        "- Media = 4.07, rango 0.4 – 9.\n",
        "- 50% central entre 3 y 5, lo cual muestra baja dispersión.\n",
        "- Valores mínimos (0.4) indican plantas muy poco productivas.\n",
        "\n",
        "### MHG (Mil Hojas de Grano o Peso de 1000 granos, g)\n",
        "\n",
        "- Media = 168.3 g, rango 127 – 216 g.\n",
        "- La mayoría entre 154 y 183 g (percentiles 25–75).\n",
        "- Variabilidad moderada (std 19.6).\n",
        "\n",
        "### GY (Grain Yield = rendimiento de grano, kg/ha o g/planta según diseño)\n",
        "\n",
        "- Media = 3419, rango 1538 – 4930.\n",
        "- 50% central entre 3126 y 3708, lo que indica una productividad media-alta.\n",
        "- Desviación (503) muestra que hay diferencias importantes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0K9J_Dk_0R2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ZyAPtDAJxibd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "1TygWN7dx50f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar variables categóricas por tipo de dato (object, category)\n",
        "categorical_vars = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "categorical_vars"
      ],
      "metadata": {
        "id": "x3UtOKCcykfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Histogramas o boxplots para ver distribuciones\n",
        "\n",
        "features = [\"PH\", \"IFP\", \"NLP\", \"NGP\", \"NGL\", \"NS\", \"MHG\", \"GY\"]\n",
        "# Define las variables que querés analizar.\n",
        "\n",
        "for col in features:\n",
        "    plt.figure(figsize=(12,4)) #Crea una nueva figura (gráfico) de 12x4 pulgadas para cada variable.\n",
        "\n",
        "    # Histograma\n",
        "    plt.subplot(1,2,1) #Divide la figura en una cuadrícula de subgráficos\n",
        "    sns.histplot(df[col], kde=True, bins=10, color=\"steelblue\")\n",
        "    # Genera un histograma de la columna col del DataFrame df:\n",
        "    # bins=10 → divide los valores en 10 intervalos (barras).\n",
        "    #color=\"steelblue\" → pinta las barras de azul acero.\n",
        "    # kde=True → añade la curva de densidad estimada para ver cómo se distribuyen los datos suavemente\n",
        "    plt.title(f\"Histograma de {col}\")\n",
        "    #Le pone un título dinámico al gráfico\n",
        "\n",
        "    # Boxplot\n",
        "    plt.subplot(1,2,2)\n",
        "    sns.boxplot(x=df[col], color=\"lightgreen\")\n",
        "    plt.title(f\"Boxplot de {col}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "d7bSHbX_4XrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretacion Histograma / Boxplot de Algunos graficos\n",
        "\n",
        "## histograma y un boxplot de la variable PH (Plant Height = Altura de planta)\n",
        "## Histograma\n",
        "- curva aproximadamente normal\n",
        "- es bastante simétrica\n",
        "## Boxplot\n",
        "- Outlier: aparece un valor aislado cerca de 95 cm\n",
        "- Bigotes (mín–máx sin outliers): se extienden desde ~48 cm hasta ~92 cm\n",
        "- Mediana: está alrededor de 67 cm\n",
        "- Caja (IQR: 25%–75%): se concentra entre 63 y 74 cm\n",
        "\n",
        "## histograma y un boxplot de IFP (longitud de inflorescencia primaria, en cm)\n",
        "## Histograma\n",
        "- Forma: distribución cercana a la normal\n",
        "## Boxplot\n",
        "- Outliers:\n",
        "- - En el extremo bajo: valores cercanos a 7.5–8 cm, plantas con inflorescencias muy cortas.\n",
        "- - En el extremo alto: varios puntos aislados por encima de 22 cm, llegando hasta ~26 cm\n",
        "- Bigotes (sin outliers): van de ~10 a ~21 cm.\n",
        "- Caja (IQR): concentra el 50% de los datos entre 13.6 y 17.3 cm, lo que indica que la mayoría está bien agrupada.\n",
        "\n",
        "# histograma y un boxplot de  NLP (Número de lóculos/vainas por planta):\n",
        "## Histograma\n",
        "- Distribución: asimétrica hacia la derecha\n",
        "## Boxplot\n",
        "- Outliers: aparecen varios puntos aislados en el extremo alto (≥115)\n",
        "- Bigotes (sin outliers): se extienden hasta valores cercanos a 110 vainas\n",
        "- Caja (IQR): entre 44 y 71 vainas, abarca el 50% de los datos centrales\n",
        "\n",
        "# histograma y un boxplot de NGP (Número de granos por planta):\n",
        "## Histograma\n",
        "- Distribución: La distribución es asimétrica positiva (sesgada a la derecha)\n",
        "\n",
        "## Boxplot\n",
        "- Outliers: aparecen múltiples puntos extremos\n",
        "- Bigotes (sin outliers): se extienden hasta valores cercanos a 250–280.\n",
        "- Caja (IQR): entre ~95 y 160 granos, donde se ubica el 50% de los datos.\n",
        "\n",
        "# histograma y un boxplot de  NGL (Número de granos por lóculo / vaina):\n",
        "## Histograma\n",
        "- Distribución: La distribución es asimétrica positiva\n",
        "\n",
        "## Boxplot\n",
        "- El cajón verde muestra que el rango intercuartílico (IQR) va aproximadamente entre 2 y 3.\n",
        "- La mediana está cerca de 2,5.\n",
        "- Existen outliers a la derecha: valores de 4, 6 y un caso extremo alrededor de 15.\n",
        "- También se observan algunos outliers menores en la parte baja, aunque pocos.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MRlvyuMJ78qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Scatterplots de features vs target\n",
        "# -------------------------\n",
        "# Scatterplots vs Rendimiento (GY)\n",
        "# -------------------------\n",
        "# Scatterplots interactivos\n",
        "for col in features:  #Recorre todas las columnas listadas en features, excepto la variable GY (porque esa ya se usa como variable de salida en el eje y).\n",
        "    if col != \"GY\":\n",
        "        fig = px.scatter(  #Crea un diagrama de dispersión\n",
        "            df,\n",
        "            x=col, #el eje X será la variable independiente\n",
        "            y=\"GY\", #el eje Y siempre será el rendimiento\n",
        "            color=\"Cultivar\",   # los puntos se colorean según la categoría de Cultivar (esto ayuda a comparar grupos).\n",
        "            title=f\"{col} vs Rendimiento (GY)\", #título dinámico con el nombre de la variable\n",
        "            template=\"plotly_white\", # estilo limpio con fondo blanco\n",
        "            trendline=\"ols\",          # Línea de regresión\n",
        "            trendline_scope=\"overall\",# dibuja una sola línea de tendencia global usando todos los cultivares juntos.\n",
        "            hover_data=df.columns  # para que muestre más info al pasar el mouse\n",
        "        )\n",
        "        fig.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Gdbfo236ctZY",
        "outputId": "5fa35d88-2fba-47de-dc4b-7ee35fde0b51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3461312531.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Scatterplots interactivos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#Recorre todas las columnas listadas en features, excepto la variable GY (porque esa ya se usa como variable de salida en el eje y).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"GY\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         fig = px.scatter(  #Crea un diagrama de dispersión\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta clave: ¿Qué relaciones lineales preliminares observan?\n",
        "\n",
        "El rendimiento en grano (GY) muestra asociaciones positivas principalmente con el número de granos por planta (NGP) y el número de legumbres por planta (NLP), aunque dichas correlaciones no son muy fuertes. Esto sugiere que el rendimiento no depende de una sola característica, sino que responde a la combinación de múltiples factores, por lo que un análisis multivariado resultará más adecuado para explicar su variabilidad.\n",
        "\n"
      ],
      "metadata": {
        "id": "5Z26MmhKemSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Preprocesamiento**  \n",
        "   - Limpieza: Manejen missing values (eliminar, imputar) y outliers (si es necesario).  \n",
        "   - Limpieza: indique cuáles features descarta. Justifique.\n",
        "   - Indique si usará o no variables categóricas. Justifique. Realice su preprocesamiento adeucado.\n",
        "   - Escalen las features (p.ej., StandardScaler) para comparar coeficientes después.  \n",
        "   - Dividan en train/test (70-30 o 80-20).  "
      ],
      "metadata": {
        "id": "A1Ajkh2O70cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y7sVuQOm76ix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolución:"
      ],
      "metadata": {
        "id": "28o4EfDd_WQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a7qdTaxy_WQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Detectar valores faltantes ---\n",
        "print(\"Valores faltantes por columna:\")\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# 2. Detectar outliers usando el criterio IQR en las variables numéricas\n",
        "outlier_info = {}\n",
        "for col in [\"PH\",\"IFP\",\"NLP\",\"NGP\",\"NGL\",\"NS\",\"MHG\",\"GY\"]:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
        "    outlier_info[col] = len(outliers)\n",
        "\n",
        "missing_values, outlier_info\n",
        "\n"
      ],
      "metadata": {
        "id": "On_Ef-tt_WQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultado: No hay valores nulos, lo que facilita el análisis.\n",
        "###Respecto a los outliers\n",
        "- PH (Altura de planta): 1 outlier.\n",
        "- IFP (Índice de fecundidad por planta): 9 outliers.\n",
        "- NLP (Nº de legumbres por planta): 5 outliers.\n",
        "- NGP (Nº de granos por planta): 9 outliers.\n",
        "- NGL (Nº de granos por legumbre): 9 outliers.\n",
        "- NS (Nº de semillas por legumbre): 4 outliers.\n",
        "- GY (Rendimiento en grano): 10 outliers.\n",
        "- MHG (Masa de 100 granos): sin outliers detectados.\n",
        "###No parecen ser errores de carga, Conviene no eliminarlos"
      ],
      "metadata": {
        "id": "gcmBSN5B9iL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza: indique cuáles features descarta. Justifique.\n",
        "\n",
        "#Las features a descartar son:\n",
        "#Repetition: No aporta a la predicción\n",
        "#Season: no voy a realizar un analisis por año.\n",
        "\n",
        "## elimino los features a descartar\n",
        "df_clean = df.drop(columns=[\"Repetition\", \"Season\"])\n",
        "# Mostrar info y primeras filas\n",
        "df_clean\n"
      ],
      "metadata": {
        "id": "KaWfcL0Y9t-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indique si usará o no variables categóricas. Justifique. Realice su preprocesamiento adecuado.\n",
        "\n",
        "> Voy a utilizar variables categóricas. En este dataset, la variable categórica relevante es **Cultivar** (variedad de soja). Su inclusión es importante, ya que permite capturar diferencias genéticas entre materiales que impactan directamente en el rendimiento. Si se descartara, se perdería información valiosa y se reduciría la capacidad predictiva del modelo.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYg_F-1e_Vro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Escalen las features (p.ej., StandardScaler) para comparar coeficientes después.\n",
        "#Para poder comparar coeficientes\n",
        "## 1- Codificar la variable categórica Cultivar (usando One-Hot Encoding).\n",
        "### 2 -Escalar las features numéricas con StandardScaler para que estén en la misma escala (media = 0, desviación estándar = 1)."
      ],
      "metadata": {
        "id": "W5b6uyrILmfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## 4. **Regresión Lineal**  \n",
        "   - Ajusten un modelo de regresión lineal (usando `sklearn.linear_model.LinearRegression`).  \n",
        "   - Obtengan:  \n",
        "     - Coeficientes (pesos) del modelo.  \n",
        "     - Evaluar métricas en el set de entrenamiento y en el de testeo: **R²**, MSE (error cuadrático medio), MAE.  \n"
      ],
      "metadata": {
        "id": "8z3BaKBi70w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir X e y\n",
        "X = df_clean.drop(columns=[\"GY\"]) #todas las variables independientes\n",
        "y = df_clean[\"GY\"] #la variable dependiente a predecir\n",
        "\n",
        "# Identificar variables categóricas y numéricas\n",
        "categorical_features = [ \"Cultivar\" ]\n",
        "numeric_features = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "# Preprocesamiento: OneHot para categóricas, dejar numéricas igual\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
        "        #convierte Cultivar en variables dummy (0/1)\n",
        "        #(drop=\"first\")evita multicolinealidad (se elimina la primera categoría como referencia)\n",
        "        (\"num\", RobustScaler(), numeric_features)  # <-- Escalar numéricas\n",
        "        # RobustScaler → normaliza las variables numéricas usando mediana y rango intercuartílico (robusto frente a outliers).\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline con preprocesamiento + regresión\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "#Aplica un preprocesamiento a los datos de entrada antes de entrenar el modelo\n",
        "#Una vez transformados los datos, entrena un modelo de regresión lineal con esas variables procesadas\n",
        "\n",
        "\n",
        "# Dividir en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "#Separa 80% de datos para entrenamiento y 20% para test.\n",
        "#random_state=42 → hace que la división sea reproducible.\n",
        "\n",
        "# Ajustar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "#Genera predicciones tanto en train como en test.\n",
        "\n",
        "# Métricas\n",
        "metrics = {\n",
        "    \"R2_train\": r2_score(y_train, y_train_pred),\n",
        "    \"R2_test\": r2_score(y_test, y_test_pred),\n",
        "    \"MSE_train\": mean_squared_error(y_train, y_train_pred),\n",
        "    \"MSE_test\": mean_squared_error(y_test, y_test_pred),\n",
        "    \"MAE_train\": mean_absolute_error(y_train, y_train_pred),\n",
        "    \"MAE_test\": mean_absolute_error(y_test, y_test_pred),\n",
        "}\n",
        "#calcula las metricas\n",
        "#R² (train/test) → mide cuánto del rendimiento (GY) logra explicar el modelo.\n",
        "#MSE (train/test) → Mean Squared Error, el error cuadrático medio.\n",
        "  #Penaliza fuerte errores grandes.\n",
        "  #Mientras más chico, mejor.\n",
        "#MAE (train/test) → Mean Absolute Error, error absoluto medio.\n",
        "#Da una idea del error promedio en las mismas unidades que la variable objetivo (ej: kg/ha).\n",
        "\n",
        "print(\"📊 Métricas del modelo reducido:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "#Recorre el diccionario e imprime cada métrica con 4 decimales\n",
        "\n",
        "\n",
        "\n",
        "# Obtener coeficientes con nombres de variables\n",
        "feature_names = model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
        "coefficients = pd.DataFrame({\n",
        "    \"Variable\": feature_names,\n",
        "    \"Coeficiente\": model.named_steps[\"regressor\"].coef_\n",
        "}).sort_values(by=\"Coeficiente\", key=abs, ascending=False)  # Ordenar por importancia\n",
        "# Recupera los nombres de las variables transformadas\n",
        "# Muestra los coeficientes estimados por la regresión lineal.\n",
        "# Ordena por magnitud absoluta → ayuda a ver qué variables tienen más impacto en el rendimiento.\n",
        "\n",
        "# Intercepto\n",
        "intercept = model.named_steps[\"regressor\"].intercept_\n",
        "#Obtiene el intercepto del modelo (valor base de GY).\n",
        "\n",
        "print(\"\\n🔹 Intercepto del modelo:\")\n",
        "print(intercept)\n",
        "\n",
        "print(\"\\n🔹 Coeficientes del modelo (ordenados por valor absoluto):\")\n",
        "print(coefficients)"
      ],
      "metadata": {
        "id": "1un0omHRTI0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5. **Importancia de Variables**  \n",
        "   - Analicen los **coeficientes** del modelo:  \n",
        "     - Valores absolutos altos → mayor impacto en el target.  \n",
        "     - Signo: Relación positiva/negativa con el target.  \n",
        "   - Comparen la magnitud de los coeficientes **escalados** (si usaron features en distintas unidades).  \n",
        "   - **5.1. Opcional**:\n",
        "     Otra forma es \"desordenar\" un feature y ver cómo empeora el modelo. Si al desordenarlo el error aumenta mucho, ese feature era importante. Usen métodos como:  \n",
        "     - **Permutation Importance** (de sklearn) para validar importancia. Más info en https://scikit-learn.org/stable/modules/permutation_importance.html\n",
        "\n"
      ],
      "metadata": {
        "id": "YpBHmWkt9Yqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolución:"
      ],
      "metadata": {
        "id": "h6IvyHmV9ccg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Valores absolutos grandes → cultivares con mayor impacto en el rendimiento esperado.\n",
        "\n",
        "*  Cultivar_96R29 IPRO (coef = -1098) Gran impacto negativo. Si se siembra este cultivar, el rendimiento esperado cae fuertemente respecto de la referencia\n",
        "\n",
        "*  Cultivar_MONSOY 8330I2X (coef = +751) → Gran impacto positivo. Asociado con altos rendimientos\n",
        "\n",
        "Coeficientes negativos → menor rendimiento esperado que la referencia.\n",
        "\n",
        "Coeficientes positivos → mayor rendimiento esperado que la referencia.\n",
        "\n",
        "###Esto indica que la elección del cultivar es la principal variable explicativa de la productividad\n",
        "\n",
        "\n",
        "\n",
        ">El modelo muestra que la elección del cultivar es, con diferencia, el factor más crítico que influye en la variable objetivo, y que ciertos tipos provocan un aumento o disminución significativo del resultado. Las variables numéricas, si bien relevantes, tienen una influencia comparativamente menor en las predicciones del modelo\n"
      ],
      "metadata": {
        "id": "GNX2zdbS9cch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6. **Reflexión**  \n",
        "   - ¿Cuáles variables son más importantes según el modelo? ¿Coincide con su análisis exploratorio?  \n",
        "   - ¿El modelo tiene buen rendimiento (R² alto, MSE bajo)? Si no, ¿a qué podría deberse?  \n",
        "\n"
      ],
      "metadata": {
        "id": "W1TnsxX69h3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolución:"
      ],
      "metadata": {
        "id": "o-4LI7_h9Z4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##¿Cuáles variables son más importantes según el modelo? ¿Coincide con su análisis exploratorio?\n",
        "\n",
        "Variables más influyentes (coeficientes más grandes en valor absoluto)\n",
        "1. Cultivar → es la variable que más explica las diferencias en rendimiento (GY).\n",
        "EJEMPLO:\n",
        "- Cultivar_96R29 IPRO → −1098\n",
        "- Cultivar_MONSOY 8330I2X → +751\n",
        "- Cultivar_NK 8100 IPRO → −720\n",
        "- Cultivar_BRASMAX BÔNUS IPRO → −644\n",
        "- Cultivar_FORTALEZA IPRO → +623\n",
        "\n",
        "Sí, porque en el EDA ya se observaba que no existía una relación lineal fuerte entre GY y ninguna variable individual..\n",
        "\n",
        "\n",
        "##¿El modelo tiene buen rendimiento (R² alto, MSE bajo)? Si no, ¿a qué podría deberse?\n",
        "\n",
        "1. el modelo tiene\n",
        "- R2_train: 0.5885,  R2_test: 0.5229  es un rendimiento moderado. El modelo explica la mitad de la variabilidad en el rendimiento.\n",
        "- El MSE y MAE son relativamente altos, lo que indica que todavía hay bastante error en las predicciones.\n",
        "\n",
        "*  El modelo tiene un rendimiento moderado (aceptable, pero no óptimo). Sirve para explicar patrones generales (ej. cultivar y NGP/MHG como variables clave), pero no alcanza precisión alta.\n",
        "\n",
        "El rendimiento podria deverse a:\n",
        "  - Relaciones no lineales entre las variables → la regresión lineal no las captura.\n",
        "- Interacciones entre variables (ej. cultivar × ambiente) que no fueron incluidas explícitamente.\n",
        "- Factores no medidos (suelo, clima, manejo agronómico) que afectan fuertemente el rendimiento y no están en el dataset.\n",
        "- Outliers que aumentan el error medio, aunque se mitigaron con RobustScaler\n",
        "\n"
      ],
      "metadata": {
        "id": "4ZvMj3P89Z4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Bonus**:  \n",
        "- Prueben eliminar variables \"poco importantes\" y reentrenar el modelo. ¿Mejora el rendimiento?  "
      ],
      "metadata": {
        "id": "cM2tFQD39LsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Revisar coeficientes ordenados por importancia\n",
        "coefficients\n",
        "#Se mira la tabla de coeficientes obtenida en el modelo original para ver cuáles tienen valores muy pequeños\n",
        "\n",
        "# 2. Definir un umbral de importancia (ejemplo: |coef| < 0.05 lo consideramos poco relevante)\n",
        "low_importance_vars = coefficients.loc[coefficients[\"Coeficiente\"].abs() < 0.05, \"Variable\"].tolist()\n",
        "print(\"Variables poco importantes a descartar:\", low_importance_vars)\n",
        "\n",
        "# 3. Generar nuevo dataset sin esas variables\n",
        "X_reduced = X.drop(columns=[col for col in numeric_features if f\"num__{col}\" in low_importance_vars])\n",
        "\n",
        "# 4. Redefinir preprocesamiento (OneHot para cultivar + numéricas filtradas)\n",
        "numeric_features_reduced = [col for col in numeric_features if f\"num__{col}\" not in low_importance_vars]\n",
        "\n",
        "\n",
        "# Preprocesamiento: OneHot para categóricas, dejar numéricas igual\n",
        "preprocessor_reduced  = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
        "        #convierte Cultivar en variables dummy (0/1)\n",
        "        #(drop=\"first\")evita multicolinealidad (se elimina la primera categoría como referencia)\n",
        "        (\"num\", RobustScaler(), numeric_features)  # <-- Escalar numéricas\n",
        "        # RobustScaler → normaliza las variables numéricas usando mediana y rango intercuartílico (robusto frente a outliers).\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 5 Pipeline con preprocesamiento + regresión\n",
        "model_reduced = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "#Aplica un preprocesamiento a los datos de entrada antes de entrenar el modelo\n",
        "#Una vez transformados los datos, entrena un modelo de regresión lineal con esas variables procesadas\n",
        "\n",
        "\n",
        "\n",
        "# Dividir en train y test\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
        "    X_reduced, y, test_size=0.2, random_state=42\n",
        ")\n",
        "#Separa 80% de datos para entrenamiento y 20% para test.\n",
        "#random_state=42 → hace que la división sea reproducible.\n",
        "\n",
        "# Ajustar el modelo\n",
        "model_reduced.fit(X_train_r, y_train_r)\n",
        "\n",
        "# Predicciones\n",
        "y_train_pred_r = model_reduced.predict(X_train_r)\n",
        "y_test_pred_r = model_reduced.predict(X_test_r)\n",
        "#Genera predicciones tanto en train como en test.\n",
        "\n",
        "metrics_reduced = {\n",
        "    \"R2_train\": r2_score(y_train_r, y_train_pred_r),\n",
        "    \"R2_test\": r2_score(y_test_r, y_test_pred_r),\n",
        "    \"MSE_train\": mean_squared_error(y_train_r, y_train_pred_r),\n",
        "    \"MSE_test\": mean_squared_error(y_test_r, y_test_pred_r),\n",
        "    \"MAE_train\": mean_absolute_error(y_train_r, y_train_pred_r),\n",
        "    \"MAE_test\": mean_absolute_error(y_test_r, y_test_pred_r),\n",
        "}\n",
        "#calcula las metricas\n",
        "#R² (train/test) → mide cuánto del rendimiento (GY) logra explicar el modelo.\n",
        "#MSE (train/test) → Mean Squared Error, el error cuadrático medio.\n",
        "  #Penaliza fuerte errores grandes.\n",
        "  #Mientras más chico, mejor.\n",
        "#MAE (train/test) → Mean Absolute Error, error absoluto medio.\n",
        "#Da una idea del error promedio en las mismas unidades que la variable objetivo (ej: kg/ha).\n",
        "\n",
        "print(\"📊 Métricas del modelo reducido:\")\n",
        "for k, v in metrics_reduced.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "#Recorre el diccionario e imprime cada métrica con 4 decimales\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mil-u2Iewns7",
        "outputId": "e2fe4dda-bdb5-4982-a4a5-f7aedb38cbef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'coefficients' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3249369564.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Revisar coeficientes ordenados por importancia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcoefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Se mira la tabla de coeficientes obtenida en el modelo original para ver cuáles tienen valores muy pequeños\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2. Definir un umbral de importancia (ejemplo: |coef| < 0.05 lo consideramos poco relevante)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'coefficients' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Conclusión:\n",
        "El modelo reducido no mejora el rendimiento. → porque todas aportan cierta información útil. Mantener todas las variables (aunque algunas sean poco relevantes) parece ser la mejor opción en este caso."
      ],
      "metadata": {
        "id": "l8R1sNrp9QyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **Tips**:  \n",
        "- Si el R² es muy bajo, revisen si hay relaciones no lineales (y consideren transformar features).  \n",
        "- Documenten cada paso: ¡la trazabilidad es clave en ciencia de datos!  \n"
      ],
      "metadata": {
        "id": "_kTXcnnw9vQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S5JHZvSnRkqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧠 TP2 REGRESION + MLP"
      ],
      "metadata": {
        "id": "wfbDtepTRSul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# REGRESIÓN CON MLP (scikit-learn)\n",
        "# ============================\n",
        "\n",
        "#  Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "print(\"Dimensiones del dataset:\", df_clean.shape)\n",
        "print(\"Columnas:\", df_clean.columns.tolist())\n",
        "df_clean.head()\n",
        "\n",
        "#  Definir variables predictoras (X) y target (y)\n",
        "target = 'GY'\n",
        "X = df_clean.drop(columns=[target])\n",
        "y = df_clean[target]\n",
        "\n",
        "#  Identificar variables numéricas y categóricas\n",
        "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "num_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "print(f\"Variables categóricas: {cat_features}\")\n",
        "print(f\"Variables numéricas: {num_features}\")\n",
        "\n",
        "#  Crear preprocesador (OneHotEncoder + RobustScaler)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features),\n",
        "        ('num', RobustScaler(), num_features)\n",
        "    ]\n",
        ")\n",
        "#OneHotEncoder a las variables categóricas (convierte texto en variables binarias).\n",
        "# RobustScaler a las numéricas (normaliza sin verse afectado por outliers).\n",
        "\n",
        "#  Crear pipeline completo: preprocesamiento + modelo MLP\n",
        "mlp = MLPRegressor(\n",
        "    hidden_layer_sizes=(64, 32), #2 capas ocultas: 64 y 32 neuronas\n",
        "    activation='relu', #Función de activación: ReLU.\n",
        "    solver='adam', #Optimizador: Adam\n",
        "    max_iter=1000, #Máximo de 1000 iteraciones.\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp)\n",
        "])\n",
        "# Preprocesa los datos.\n",
        "\n",
        "\n",
        "#  Dividir datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "#  Entrenar el modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#  Evaluar\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "#Calcula métricas de desempeño , error promedio cuadrático y  coeficiente de determinación qué tan bien se ajusta el modelo a los datos (1.0 = perfecto)\n",
        "\n",
        "print(f\"\\nError cuadrático medio (MSE): {mse:.4f}\")\n",
        "print(f\"Coeficiente de determinación (R²): {r2:.4f}\")\n",
        "\n",
        "#  Gráfico: reales vs predichos\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicción (GY)\")\n",
        "plt.title(\"GY: valores reales vs predichos\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#Si los puntos siguen la línea roja diagonal, el modelo predice bien\n",
        "\n",
        "#  Curva de pérdida\n",
        "mlp_model = model.named_steps['mlp']\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(mlp_model.loss_curve_)\n",
        "plt.title(\"Curva de pérdida durante el entrenamiento\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#Muestra cómo disminuye la pérdida (error) durante el entrenamiento. Una curva descendente indica aprendizaje; si se estabiliza, el modelo ha convergido."
      ],
      "metadata": {
        "id": "xEQv6jkPTBOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Caso base (modelo equilibrado)\n",
        "\n",
        "MSE: 124,221.48\n",
        "\n",
        "R²: 0.5202\n",
        "\n",
        "➡️ El modelo logra explicar alrededor del 52% de la variabilidad, lo que sugiere un ajuste moderado: no perfecto, pero razonable.\n",
        "No hay evidencia clara de sobreajuste ni subajuste en este punto."
      ],
      "metadata": {
        "id": "csEfrIkqY-ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Presentar un caso donde la MLP sobreajuste"
      ],
      "metadata": {
        "id": "0ye53D4CUibl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CASO DE SOBREAJUSTE (OVERFITTING)\n",
        "# ==============================\n",
        "\n",
        "#  Dividir datos (poco entrenamiento para provocar sobreajuste)\n",
        "# Sólo 20% para entrenamiento (el 80% restante es para prueba/test)\n",
        "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
        "    X, y, test_size=0.8, random_state=42\n",
        ")\n",
        "\n",
        "#  Crear un modelo MLP MUY grande (demasiada capacidad)\n",
        "mlp_overfit = MLPRegressor(\n",
        "    hidden_layer_sizes=(256, 128, 64, 32, 16),  # muchas capas y neuronas\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=3000, #3000 iteracciones\n",
        "    random_state=42,\n",
        "    tol=1e-5 # Tolerancia baja (tol=1e-5), para que el entrenamiento siga hasta alcanzar una pérdida muy pequeña\n",
        ")\n",
        "\n",
        "#  Crear pipeline con preprocesamiento + modelo\n",
        "model_overfit = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp_overfit)\n",
        "])\n",
        "#El Pipeline garantiza que se apliquen los mismos pasos de preprocesamiento (OneHotEncoder + escalado) en los datos de entrenamiento y prueba.\n",
        "\n",
        "#  Entrenar\n",
        "print(\"Entrenando MLP con capacidad alta y pocos datos...\")\n",
        "model_overfit.fit(X_train_small, y_train_small)\n",
        "#Con tan pocos datos y tanta capacidad, el modelo va a “aprender” perfectamente los datos de entrenamiento —es decir, los memoriza.\n",
        "\n",
        "#  Evaluar en train y test\n",
        "y_train_pred = model_overfit.predict(X_train_small)\n",
        "y_test_pred = model_overfit.predict(X_test_small)\n",
        "\n",
        "# Se calculan las métricas en ambos conjuntos:\n",
        "mse_train = mean_squared_error(y_train_small, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test_small, y_test_pred)\n",
        "r2_train = r2_score(y_train_small, y_train_pred)\n",
        "r2_test = r2_score(y_test_small, y_test_pred)\n",
        "\n",
        "print(\"\\n=== RESULTADOS DE SOBREAJUSTE ===\")\n",
        "print(f\"Entrenamiento → MSE: {mse_train:.4f} | R²: {r2_train:.4f}\")\n",
        "print(f\"Prueba        → MSE: {mse_test:.4f} | R²: {r2_test:.4f}\")\n",
        "\n",
        "#  Gráfico: valores reales vs predichos (test)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test_small, y_test_pred, alpha=0.7, color='orange')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicción (GY)\")\n",
        "plt.title(\"Caso de sobreajuste - Datos de prueba\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#  Curva de pérdida\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(model_overfit.named_steps['mlp'].loss_curve_)\n",
        "plt.title(\"Curva de pérdida (sobreajuste)\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "40n1mxZpUiCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo es demasiado complejo para la cantidad de datos. Aprende el ruido del conjunto de entrenamiento y generaliza mal a datos nuevos. R Train2​  es alto, R Test2​  es significativamente bajo.  MSE Train bajo, MSE Test alto\n",
        "\n",
        "## En el conjunto de entrenamiento\n",
        "\n",
        "MSE = 21.6 → el error promedio es prácticamente nulo.\n",
        "\n",
        "R² = 0.9999 → el modelo explica el 99.99% de la variabilidad de los datos de entrenamiento.\n",
        "\n",
        "👉 Eso significa que el modelo ha memorizado completamente los datos que vio durante el entrenamiento.\n",
        "Es decir, ajustó a la perfección los pocos puntos de entrenamiento.\n",
        "\n",
        "## En el conjunto de prueba\n",
        "\n",
        "MSE = 442,161.55 → el error medio cuadrático es enorme, miles de veces mayor que en entrenamiento.\n",
        "\n",
        "R² = -0.8440 → valor negativo, lo cual es muy malo.\n",
        "\n",
        "⚠️ Cuando R² < 0, significa que el modelo predice peor que una línea horizontal constante (es decir, peor que simplemente predecir el promedio de los valores de “GY”).\n",
        "\n",
        "En otras palabras:\n",
        "\n",
        "La red neuronal no aprendió a generalizar. Solo repite lo que ve en el entrenamiento y falla con datos nuevos.\n"
      ],
      "metadata": {
        "id": "KOAX7MmYZ9wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 2.3 Presentar un caso donde la MLP subajuste"
      ],
      "metadata": {
        "id": "wX2HfZWpW2j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CASO DE SUBAJUSTE (UNDERFITTING)\n",
        "# ==============================\n",
        "\n",
        "#  Dividir datos (división estándar)\n",
        "# Usaremos una división estándar para que haya suficientes datos de entrenamiento\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42  # 80% entrenamiento, 20% prueba\n",
        ")\n",
        "\n",
        "#  Crear un modelo MLP MUY pequeño (poca capacidad)\n",
        "# Una sola capa con muy pocas neuronas y pocas iteraciones.\n",
        "mlp_underfit = MLPRegressor(\n",
        "    hidden_layer_sizes=(5,),  # Solo 5 neuronas en 1 capa (baja capacidad)\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=50,              # Muy pocas iteraciones (detiene el aprendizaje pronto)\n",
        "    random_state=42,\n",
        "    tol=0.1                   # Mayor tolerancia para que se detenga rápidamente\n",
        ")\n",
        "\n",
        "#  Crear pipeline con preprocesamiento + modelo\n",
        "model_underfit = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp_underfit)\n",
        "])\n",
        "\n",
        "#  Entrenar\n",
        "print(\"Entrenando MLP con capacidad baja y pocas iteraciones...\")\n",
        "model_underfit.fit(X_train, y_train) #Ajusta los parámetros del modelo a los datos de entrenamiento.\n",
        "#Pero como el modelo tiene poca capacidad y pocas iteraciones,aprende solo patrones muy generales o incluso ninguno.\n",
        "\n",
        "#  Evaluar en train y test\n",
        "y_train_pred = model_underfit.predict(X_train)\n",
        "y_test_pred = model_underfit.predict(X_test)\n",
        "\n",
        "#calcula las metricas\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n=== RESULTADOS DE SUBAJUSTE ===\")\n",
        "print(f\"Entrenamiento → MSE: {mse_train:.4f} | R²: {r2_train:.4f}\")\n",
        "print(f\"Prueba        → MSE: {mse_test:.4f} | R²: {r2_test:.4f}\")\n",
        "\n",
        "#  Gráfico: valores reales vs predichos (test)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, color='purple')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicción (GY)\")\n",
        "plt.title(\"Caso de subajuste - Datos de prueba\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#  Curva de pérdida\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(model_underfit.named_steps['mlp'].loss_curve_)\n",
        "plt.title(\"Curva de pérdida (subajuste)\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OGGIaTLyW7bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo MLP configurado con una sola capa oculta de 5 neuronas, pocas iteraciones y una alta tolerancia presentó un rendimiento deficiente tanto en entrenamiento como en prueba (MSE elevados y R² negativos).\n",
        "Esto indica que el modelo tiene insuficiente capacidad y entrenamiento para capturar las relaciones existentes en los datos.\n",
        "En consecuencia, las predicciones son prácticamente aleatorias o muy cercanas al promedio, sin reflejar patrones significativos.\n",
        "\n",
        "🐢Caso de subajuste (Underfitting)\n",
        "- Entrenamiento → MSE: 11,945,301.75 | R²: -46.68\n",
        "- Prueba → MSE: 11,869,827.10 | R²: -44.84\n",
        "\n",
        "➡️ El modelo tiene errores muy grandes y R² negativos tanto en entrenamiento como en prueba.\n",
        "Esto demuestra que no aprendió los patrones de los datos, produciendo predicciones cercanas al promedio sin relación real con la variable objetivo.\n",
        "Por lo tanto, subajusta (underfitting).\n",
        "\n"
      ],
      "metadata": {
        "id": "FsPaqIu5Ztjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 2.4 Presentar el caso donde cree que la MLP funciona de forma aceptable"
      ],
      "metadata": {
        "id": "-PCfqlFTXhwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# CASO DE RENDIMIENTO ACEPTABLE (BUEN AJUSTE)\n",
        "# ====================================\n",
        "\n",
        "#  Dividir datos (división estándar)\n",
        "# Usamos una división estándar para tener suficientes datos de entrenamiento y prueba.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42  # 80% entrenamiento, 20% prueba\n",
        ")\n",
        "\n",
        "#  Crear un modelo MLP con capacidad MODERADA\n",
        "mlp_balanced = MLPRegressor(\n",
        "    hidden_layer_sizes=(64, 32, 16),  # 3 capas ocultas con 64, 32 y 16 neuronas → suficiente capacidad para aprender, pero no excesiva\n",
        "    activation='relu',                #Función de activación ReLU, que permite modelar relaciones no lineales.\n",
        "    solver='adam',\n",
        "    alpha=0.001,                      # Regularización L2 para penalizar pesos y mejorar la generalización\n",
        "    max_iter=1000,                    # Máximo de 1000 iteraciones: límite razonable para permitir la convergencia\n",
        "    n_iter_no_change=20,              # Parada anticipada: si el score no mejora en 20 iteraciones, se detiene\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#  Crear pipeline con preprocesamiento + modelo\n",
        "model_balanced = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp_balanced)\n",
        "])\n",
        "# Combina el preprocesamiento de datos (OneHotEncoder para variables categóricas + escalado para numéricas) con el modelo neuronal MLP.\n",
        "# Así, el flujo completo de datos se maneja automáticamente\n",
        "\n",
        "#  Entrenar\n",
        "print(\"Entrenando MLP con capacidad moderada y regularización...\")\n",
        "model_balanced.fit(X_train, y_train)\n",
        "\n",
        "#  Evaluar en train y test\n",
        "y_train_pred = model_balanced.predict(X_train)\n",
        "y_test_pred = model_balanced.predict(X_test)\n",
        "\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "#Se calcula el error y la capacidad de predicción en entrenamiento y prueba:\n",
        "\n",
        "print(\"\\n=== RESULTADOS DE RENDIMIENTO ACEPTABLE ===\")\n",
        "print(f\"Entrenamiento → MSE: {mse_train:.4f} | R²: {r2_train:.4f}\")\n",
        "print(f\"Prueba        → MSE: {mse_test:.4f} | R²: {r2_test:.4f}\")\n",
        "print(\"---\")\n",
        "print(f\"Diferencia de R² (Train - Test): {r2_train - r2_test:.4f}\")\n",
        "\n",
        "#  Gráfico: valores reales vs predichos (test)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, color='green')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
        "plt.xlabel(\"Valor real (GY)\")\n",
        "plt.ylabel(\"Predicción (GY)\")\n",
        "plt.title(\"Caso de ajuste aceptable - Datos de prueba\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#  Curva de pérdida\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(model_balanced.named_steps['mlp'].loss_curve_)\n",
        "plt.title(\"Curva de pérdida (ajuste aceptable)\")\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ALtKTbYxXjx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo tiene una capacidad adecuada y generaliza bien. El rendimiento en entrenamiento y prueba es similar y alto. La diferencia entre ellos es mínima, lo que indica que el modelo ha aprendido bien los patrones del entrenamiento y tiene una excelente capacidad de generalización.  R² Train ≈ R² Test,  MSE bajos y parecidos\n",
        "\n",
        "🧠 Interpretación conceptual\n",
        "\n",
        "El Error cuadrático medio (MSE) es relativamente bajo y similar en entrenamiento y prueba, lo que indica que el modelo no está ni sobreajustando ni subajustando.\n",
        "\n",
        "El R² ≈ 0.6 en ambos conjuntos sugiere que el modelo explica aproximadamente el 60% de la variabilidad de la variable objetivo (GY), lo cual se considera un ajuste razonablemente bueno en contextos con datos reales (donde siempre existe ruido o variabilidad no explicada).\n",
        "\n"
      ],
      "metadata": {
        "id": "oVF-7H51ZmAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "2.5 Agregue sus conclusiones comparando la experiencia y resultados del modelo de regresión lineal con el modelo del punto 2.4"
      ],
      "metadata": {
        "id": "_Wk-V2qZZb0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis Comparativo\n",
        "### Rendimiento Predictivo (R2):\n",
        "-  La MLP logra un R 2\n",
        "  de prueba (0.5973) que es ligeramente superior al de la Regresión Lineal (0.5229). La mejora es modesta, pero indica que la MLP está capturando más variabilidad de la variable objetivo (GY).\n",
        "- Ambos modelos tienen un R 2\n",
        "  por debajo de 0.60, lo que sugiere que ambos modelos están subajustando en cierta medida, es decir, no están capturando completamente la complejidad de los datos (la varianza explicada sigue siendo baja).\n",
        "\n",
        "### Precisión del Error (MSE):\n",
        "- El MSE de la MLP (104270) es significativamente menor que el de la Regresión Lineal (123529), lo que significa que, en promedio, el error cuadrático de la MLP es menor. Esto confirma que la MLP es una mejor herramienta predictiva, aunque la ganancia en R 2  no sea dramática.\n",
        "\n",
        "### Capacidad de Generalización (Diferencia R 2 ):\n",
        "\n",
        "- Este es el punto más fuerte de la MLP. La diferencia entre R Train2​  y R\n",
        "Test2​  es de solo 0.0017 para la MLP, mientras que en la Regresión Lineal es de 0.0656. Esto indica que la MLP ha logrado un equilibrio de generalización casi perfecto. La MLP no está aprendiendo el ruido y funciona casi idénticamente en datos vistos y no vistos. La Regresión Lineal, aunque simple, mostró una caída más pronunciada en la generalización.\n",
        "\n",
        "\n",
        "###  Conclusión Final\n",
        "\n",
        "El modelo de Red Neuronal MLP (con R2 ≈0.60) es el modelo superior para este dataset. Ofreciendo un balance óptimo entre precisión predictiva y capacidad de generalización, frente a la Regresión Lineal que resulta más limitada en ambos aspectos.\n"
      ],
      "metadata": {
        "id": "S9iCKgMubPr7"
      }
    }
  ]
}